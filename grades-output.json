[
  {
    "id": "_ENHANCEMENT_TODO",
    "filePath": "knowledge-base/models/_ENHANCEMENT_TODO.md",
    "category": "knowledge-base",
    "isModel": true,
    "title": "_ENHANCEMENT_TODO",
    "grades": {
      "importance": 1,
      "quality": 3,
      "llmSummary": "This is a project management file that tracks which analytical models need enhancement to match style guide standards. It provides workflow instructions for systematic improvement of model documentation quality.",
      "ratings": {
        "novelty": 1,
        "rigor": 2,
        "actionability": 4,
        "completeness": 3
      },
      "reasoning": "This is purely operational documentation for maintaining the knowledge base, not substantive AI safety content. While well-organized and actionable for project management, it has no direct relevance to understanding AI existential risk. The rigor is low as it's procedural rather than analytical, but it's reasonably complete for its administrative purpose."
    }
  },
  {
    "id": "_STYLE_GUIDE",
    "filePath": "knowledge-base/models/_STYLE_GUIDE.md",
    "category": "knowledge-base",
    "isModel": true,
    "title": "_STYLE_GUIDE",
    "grades": {
      "importance": 3,
      "quality": 4,
      "llmSummary": "This style guide establishes standards for analytical models in AI safety, emphasizing information density through quantitative analysis, visual structure, and detailed frameworks. It provides comprehensive formatting requirements including mandatory sections, table standards, diagram specifications, and anti-patterns to avoid.",
      "ratings": {
        "novelty": 2,
        "rigor": 4,
        "actionability": 5,
        "completeness": 4
      },
      "reasoning": "High quality style guide with detailed, actionable specifications for model creation. While not novel (standard documentation practice), it's rigorous in its requirements and highly actionable with specific checklists and examples. Importance is moderate as it's infrastructure rather than direct AI safety content. Completeness is strong but could benefit from examples of completed models following the guidelines."
    }
  },
  {
    "id": "ai-risk-portfolio-analysis",
    "filePath": "knowledge-base/models/ai-risk-portfolio-analysis.mdx",
    "category": "knowledge-base",
    "isModel": true,
    "title": "AI Risk Portfolio Analysis",
    "grades": {
      "importance": 5,
      "quality": 4,
      "llmSummary": "This portfolio framework estimates resource allocation across AI risk categories, finding misalignment accounts for 40-70% of existential risk, misuse 15-35%, and structural risks 10-25%. It provides actionable guidance for funders and researchers on where marginal resources have highest impact.",
      "ratings": {
        "novelty": 4,
        "rigor": 3,
        "actionability": 5,
        "completeness": 3
      },
      "reasoning": "Essential framework for the field (importance 5) addressing core strategic questions. Quality is high (4) with comprehensive analysis, clear tables, and actionable recommendations, though some claims lack detailed justification. High novelty (4) as few attempts exist to quantify risk portfolio allocation. Moderate rigor (3) due to acknowledged high uncertainty and limited empirical grounding. Excellent actionability (5) with specific guidance for different actors. Completeness (3) covers main categories but could expand on interaction effects and comparative advantage analysis."
    }
  },
  {
    "id": "authentication-collapse-timeline",
    "filePath": "knowledge-base/models/authentication-collapse-timeline.mdx",
    "category": "knowledge-base",
    "isModel": true,
    "title": "Authentication Collapse Timeline Model",
    "grades": {
      "importance": 5,
      "quality": 5,
      "llmSummary": "This model analyzes when AI-generated content will make digital verification systems fail, tracking decay rates across text (already at random chance), images (65-70% accuracy declining 5-10% annually), and audio/video. It projects complete authentication collapse by 2030-2035 absent major defensive coordination, with legal systems facing crisis when detection falls below evidentiary thresholds.",
      "ratings": {
        "novelty": 4,
        "rigor": 4,
        "actionability": 4,
        "completeness": 5
      },
      "reasoning": "Core topic for AI safety - authentication failure could undermine institutions, democracy, and social trust. Excellent quality with comprehensive analysis, quantitative projections, scenario modeling, and detailed domain impacts. Strong novelty in systematic timeline modeling and mathematical formulation of arms race dynamics. Good rigor with empirical data and structured methodology, though some projections rely on limited historical data. High actionability with specific intervention windows and policy recommendations. Exceptionally complete coverage across technical, institutional, and societal dimensions."
    }
  },
  {
    "id": "authoritarian-tools-diffusion",
    "filePath": "knowledge-base/models/authoritarian-tools-diffusion.mdx",
    "category": "knowledge-base",
    "isModel": true,
    "title": "Authoritarian Tools Diffusion Model",
    "grades": {
      "importance": 5,
      "quality": 5,
      "llmSummary": "This model analyzes how AI surveillance technologies spread from developers to authoritarian regimes through commercial sales, development assistance, joint ventures, reverse engineering, and illicit acquisition. It identifies semiconductor supply chains as the highest-leverage intervention point but estimates this advantage will erode within 5-10 years as domestic manufacturing develops.",
      "ratings": {
        "novelty": 3,
        "rigor": 4,
        "actionability": 4,
        "completeness": 4
      },
      "reasoning": "Essential topic for AI safety given the role of surveillance tech in entrenching authoritarianism and reducing democratic transitions. Extremely well-developed with comprehensive framework, quantified estimates, detailed case studies, and practical intervention analysis. While the basic concept of technology diffusion isn't novel, the specific application to AI surveillance tools with detailed pathways and control points provides valuable insights. Highly rigorous with good data, clear reasoning, and balanced scenario analysis. Very actionable for policymakers with specific intervention strategies ranked by effectiveness. Nearly complete coverage of the domain, though slightly cuts off at the end."
    }
  }
]