---
title: "Parameters"
description: "Component parameters that determine the root factors shaping AI transition outcomes. Each parameter can be measured, tracked, and influenced through interventions."
sidebar:
  label: Overview
  order: 0
lastEdited: "2026-01-03"
tableOfContents: false
fullWidth: true
---
import {EntityLink} from '../../../../components/wiki';

import FullWidthLayout from '../../../../components/FullWidthLayout';

<FullWidthLayout />

Parameters are the measurable components that determine root factors like <EntityLink id="__index__/ai-transition-model/factors/misalignment-potential">Misalignment Potential</EntityLink> and <EntityLink id="__index__/ai-transition-model/factors/civilizational-competence">Civilizational Competence</EntityLink>. Each parameter has:

- **Current state** with quantified metrics
- **Trajectory** showing improvement or decline
- **Factors that increase/decrease** the parameter
- **Connection to outcomes** through parent factors

See the <EntityLink id="__index__/ai-transition-model">interactive AI transition model</EntityLink> for a visual representation.

---

## Parameters by Root Factor

### Misalignment Potential

Parameters determining the likelihood of AI systems pursuing unintended goals.

| Parameter | Description | Current State |
|-----------|-------------|---------------|
| <EntityLink id="alignment-robustness">Alignment Robustness</EntityLink> | How reliably AI systems pursue intended goals | 12-78% alignment faking in studies |
| <EntityLink id="safety-capability-gap">Safety-Capability Gap</EntityLink> | Lag between capability and safety advances | Widening (70-80% timeline compression) |
| <EntityLink id="interpretability-coverage">Interpretability Coverage</EntityLink> | Fraction of model behavior we can explain | ~10% coverage, improving |
| <EntityLink id="human-oversight-quality">Human Oversight Quality</EntityLink> | Effectiveness of human supervision | Declining relative to AI speed |
| <EntityLink id="safety-culture-strength">Safety Culture Strength</EntityLink> | Organizational prioritization of safety | Variable (6-12% of R&D) |

### Misuse Potential

Parameters determining vulnerability to intentional harmful use of AI.

| Parameter | Description | Current State |
|-----------|-------------|---------------|
| <EntityLink id="ai-control-concentration">AI Control Concentration</EntityLink> | Distribution of power over AI development | Concentrating (fewer than 20 frontier-capable orgs) |
| <EntityLink id="biological-threat-exposure">Biological Threat Exposure</EntityLink> | Vulnerability to AI-enabled bioweapons | ~25% dangerous sequence detection |
| <EntityLink id="cyber-threat-exposure">Cyber Threat Exposure</EntityLink> | Vulnerability to AI-enabled cyberattacks | 87% of orgs faced AI attacks (2024) |

### Transition Turbulence

Parameters determining background instability during the AI transition.

| Parameter | Description | Current State |
|-----------|-------------|---------------|
| <EntityLink id="economic-stability">Economic Stability</EntityLink> | Resilience to AI-driven economic changes | 40-60% job exposure in advanced economies |
| <EntityLink id="racing-intensity">Racing Intensity</EntityLink> | Competitive pressure prioritizing speed over safety | High (safety budgets dropped 12% to 6%) |

### Civilizational Competence

Parameters determining humanity's collective ability to navigate AI development wisely.

#### Governance

| Parameter | Description | Current State |
|-----------|-------------|---------------|
| <EntityLink id="governance">Governance</EntityLink> | Aggregate capacity to steer AI development | Cross-cutting aggregate |
| <EntityLink id="regulatory-capacity">Regulatory Capacity</EntityLink> | Government ability to regulate AI | 600:1 resource disparity |
| <EntityLink id="institutional-quality">Institutional Quality</EntityLink> | Health of AI governance institutions | Under pressure (capture concerns) |
| <EntityLink id="international-coordination">International Coordination</EntityLink> | Global cooperation on AI governance | Fragmenting (Paris 2025 refusal) |
| <EntityLink id="coordination-capacity">Coordination Capacity</EntityLink> | Stakeholder cooperation on safety | Growing but limited |

#### Epistemic Foundation

| Parameter | Description | Current State |
|-----------|-------------|---------------|
| [Epistemics](/ai-transition-model/parameters/epistemics/) | Aggregate capacity for clear thinking | Aggregate overview |
| <EntityLink id="epistemic-health">Epistemic Health</EntityLink> | Ability to distinguish truth from falsehood | 50%+ AI-generated content |
| <EntityLink id="societal-trust">Societal Trust</EntityLink> | Confidence in institutions and experts | 77% (1964) to 22% (2024) |
| <EntityLink id="reality-coherence">Reality Coherence</EntityLink> | Shared beliefs about basic facts | 47% to 12% partisan news overlap |
| <EntityLink id="information-authenticity">Information Authenticity</EntityLink> | Ability to verify content is genuine | 55% human deepfake detection |
| <EntityLink id="preference-authenticity">Preference Authenticity</EntityLink> | Whether preferences reflect genuine values | 5B+ users on engagement-optimizing systems |

#### Societal Adaptability

| Parameter | Description | Current State |
|-----------|-------------|---------------|
| <EntityLink id="adaptability">Adaptability</EntityLink> | Aggregate capacity to absorb AI changes | Aggregate overview |
| <EntityLink id="societal-resilience">Societal Resilience</EntityLink> | Ability to recover from AI disruptions | Declining (outage costs rising) |
| <EntityLink id="human-expertise">Human Expertise</EntityLink> | Maintenance of human skills | Declining (skill atrophy evidence) |
| <EntityLink id="human-agency">Human Agency</EntityLink> | Meaningful control over life decisions | Declining (70% YouTube, 75% hiring mediated) |

---

## Related Pages

- <EntityLink id="__index__/ai-transition-model/factors">Root Factors</EntityLink> — The five root factors these parameters determine
- <EntityLink id="__index__/ai-transition-model/outcomes">Outcomes</EntityLink> — Ultimate outcomes shaped by these parameters
- <EntityLink id="__index__/ai-transition-model">AI Transition Model</EntityLink> — Full model overview
