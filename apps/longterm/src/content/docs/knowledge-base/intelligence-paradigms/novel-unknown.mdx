---
title: "Novel / Unknown Approaches"
description: "Consideration of potential breakthrough paradigms not yet discovered or recognized. Covers historical paradigm shifts, potential sources of novelty, and why we should maintain epistemic humility about future intelligence architectures."
sidebar:
  label: Novel/Unknown
  order: 17
quality: 3
lastEdited: "2025-01-21"
importance: 55
---

import {Mermaid} from '../../../../components/wiki';

## Overview

This category represents the **probability mass we should assign to approaches not yet discovered or not included in our current taxonomy**. History shows that transformative technologies often come from unexpected directions, and intellectual humility requires acknowledging this.

While we can't predict specific unknown approaches, we can reason about:
- Historical precedents for paradigm shifts
- Current areas where breakthroughs might emerge
- What "unknown unknown" scenarios might look like

Estimated probability of being dominant at transformative AI: **1-5%** (inherently uncertain)

## Why Include This Category

<Mermaid client:load chart={`
flowchart TB
    subgraph known["Known Approaches"]
        transformers["Transformers"]
        moe["Sparse/MoE"]
        ssm["SSMs"]
        neuro["Neuromorphic"]
        other["Other Known"]
    end

    subgraph unknown["Unknown Territory"]
        notyet["Not Yet Discovered"]
        overlooked["Overlooked Ideas"]
        combinations["Novel Combinations"]
        physics["New Physics?"]
    end

    known -->|"Sum to ~95-99%"| total["Total Probability"]
    unknown -->|"Residual 1-5%"| total
`} />

### Arguments for Allocating Probability Here

| Argument | Explanation |
|----------|-------------|
| **Historical track record** | Major breakthroughs often unexpected |
| **Epistemic humility** | We don't know what we don't know |
| **Active research** | Many smart people working on new ideas |
| **Combinatorial space** | Possible architectures vastly exceed explored |

### Arguments Against High Probability

| Argument | Explanation |
|----------|-------------|
| **Current approaches working** | Transformers haven't hit hard ceiling |
| **Incremental progress** | Breakthroughs usually build on existing work |
| **Selection effects** | Best ideas tend to be discovered early |
| **Time constraints** | Limited years until TAI (if near) |

## Historical Precedents

### Past Paradigm Shifts in AI

| Shift | From | To | Was It Predicted? |
|-------|------|-----|-------------------|
| Neural network revival | Symbolic AI | Deep learning | Partially (by few) |
| Attention/transformers | RNNs/CNNs | Transformers | Somewhat surprising |
| Scaling laws | "Need new ideas" | "Just scale" | Surprising to many |
| In-context learning | Fine-tuning | Prompting | Not predicted |
| RLHF effectiveness | Supervised only | RLHF | Somewhat expected |

### Lessons from History

| Lesson | Implication |
|--------|-------------|
| **Old ideas revive** | Attention was known; transformers made it work |
| **Combinations matter** | Transformer = attention + layernorm + scale |
| **Empirical surprises** | In-context learning emerged unexpectedly |
| **Scaling surprises** | Scaling laws weren't obvious a priori |

## Potential Sources of Novelty

### Areas Where Breakthroughs Might Emerge

| Area | Potential | Current Status |
|------|-----------|----------------|
| **Learning algorithms** | Beyond backprop/SGD | Active research |
| **Architectures** | Beyond attention | SSMs, etc. |
| **Objective functions** | Beyond token prediction | Minimal progress |
| **Training paradigms** | Beyond supervised/RL | Emerging ideas |
| **Hardware-software co-design** | Novel compute substrates | Neuromorphic, analog |

### Specific Speculative Directions

| Direction | Description | Probability |
|-----------|-------------|-------------|
| **Algorithmic breakthroughs** | New training methods | Low-medium |
| **Physics-based computing** | Quantum, analog, optical | Very low |
| **Biological insights** | From neuroscience | Low |
| **Emergent capabilities** | Unexpected abilities at scale | Ongoing |
| **AI-discovered AI** | AI designs better architectures | Possible near-term |

## What Novel Approaches Might Look Like

### Possible Characteristics

| Characteristic | Explanation |
|----------------|-------------|
| **More efficient** | Orders of magnitude less compute |
| **Different training** | Not gradient descent |
| **Different objectives** | Not next-token prediction |
| **Different hardware** | Not GPUs |
| **Different capabilities** | Strong at what transformers struggle with |

### Warning Signs We Might Miss Something

| Sign | What It Suggests |
|------|------------------|
| Fundamental capability ceilings | Current approaches hitting limits |
| Efficiency gaps with biology | Brains use far less energy |
| Certain tasks remain hard | Reasoning, planning, learning efficiency |
| Theoretical gaps | Don't understand why current methods work |

## Safety Implications

### Why Novel Approaches Are Concerning

| Concern | Explanation |
|---------|-------------|
| **Unpredictability** | Can't prepare for unknown risks |
| **Rapid capability jumps** | New paradigm might be much more capable |
| **Different failure modes** | Safety research might not transfer |
| **Misplaced confidence** | We might assume current understanding applies |

### Why They Might Be Better

| Potential Benefit | Explanation |
|-------------------|-------------|
| **Designed for safety** | New approaches could prioritize interpretability |
| **Different incentives** | Might emerge from safety-focused research |
| **Better understanding** | New paradigms might be more theoretically grounded |
| **Natural alignment** | Could have built-in alignment properties |

## Research Questions

### What Should We Monitor?

| Area | What to Watch |
|------|---------------|
| **Academic ML** | Novel architectures, theoretical results |
| **Industry labs** | Unpublished breakthroughs |
| **Interdisciplinary** | Physics, neuroscience, mathematics |
| **AI-for-AI** | AI systems discovering new AI methods |

### How to Prepare for Unknown Unknowns?

| Strategy | Rationale |
|----------|-----------|
| **General safety research** | Focus on principles that transfer |
| **Monitoring** | Track developments broadly |
| **Flexibility** | Don't overfit to transformer-specific approaches |
| **Worst-case planning** | Assume capabilities might jump unexpectedly |

## Bayesian Reasoning

### How to Update

| Observation | Update Direction |
|-------------|------------------|
| Transformers continue scaling | Novel approaches less likely near-term |
| Hard ceiling hit | Novel approaches more likely |
| Theoretical breakthrough | Pay attention to specific direction |
| AI discovers better architecture | Accelerates unknown-unknown risk |

### Why 1-5% Is Reasonable

```
Consider:
- Known approaches seem to be working
- But history shows paradigm shifts happen
- Timeline to TAI is uncertain
- Space of possible approaches is vast

1-5% reflects: "Probably current approaches, but not certain"
```

## Key Uncertainties

1. **How locked-in is the current paradigm?** Transformers might be like "the wheel" (fundamental) or like "vacuum tubes" (soon replaced).

2. **How much does understanding matter?** We might hit limits because we don't understand what we're doing.

3. **Will AI-discovered AI come before TAI?** AI might design better architectures before human-level AI.

4. **How would we recognize a breakthrough?** New paradigms often don't look impressive at first.

## Related Pages

- [Dense Transformers](/knowledge-base/intelligence-paradigms/dense-transformers) - The current dominant paradigm
- [SSM/Mamba](/knowledge-base/intelligence-paradigms/ssm-mamba) - A recent alternative architecture
- [Neuromorphic](/knowledge-base/intelligence-paradigms/neuromorphic) - Hardware-level novelty
- [Neuro-Symbolic](/knowledge-base/intelligence-paradigms/neuro-symbolic) - Combining known approaches
