---
title: Model Registries
description: Centralized databases of frontier AI models that enable governments to track development, enforce safety requirements, and coordinate international oversight—serving as foundational infrastructure for AI governance analogous to drug registries for the FDA.
sidebar:
  order: 12
quality: 51
lastEdited: 2025-12-28
importance: 75.5
llmSummary: Analyzes model registries as foundational governance infrastructure across US (≥10^26 FLOP threshold), EU (≥10^25 FLOP), and state-level implementations, showing they enable pre-deployment review and incident tracking but don't prevent harm directly. Provides specific implementation recommendations including 30-90 day pre-deployment notification and 72-hour incident reporting, with medium-high confidence that registries improve visibility and incident learning.
pageTemplate: knowledge-base-response
todos:
  - Complete 'Core Design Principles' section
  - Complete 'How It Works' section
ratings:
  novelty: 4
  rigor: 6.5
  actionability: 7
  completeness: 7.5
metrics:
  wordCount: 620
  citations: 0
  tables: 18
  diagrams: 1
---
import {Mermaid, EntityLink, DataExternalLinks} from '../../../../../components/wiki';

<DataExternalLinks pageId="model-registries" client:load />

## Overview

Model registries represent a foundational governance tool for managing risks from advanced AI systems. Like drug registries that enable pharmaceutical regulation or aircraft registries that support aviation safety, AI model registries would create centralized databases containing information about frontier AI systems—their capabilities, training details, deployment contexts, and safety evaluations. This infrastructure provides governments with the visibility necessary to implement more sophisticated AI governance measures.

The policy momentum is significant. The U.S. Executive Order on AI (October 2023) mandated quarterly reporting for models trained above 10^26 FLOP. The EU AI Act requires registration of high-risk AI systems and general-purpose AI models. California's Transparency in Frontier AI Act (TFAIA) mandates annual publication of comprehensive "Frontier AI Frameworks" by large developers. New York's RAISE Act requires incident reporting within 72 hours. These requirements create the skeleton of a registry system, though implementation remains fragmented and early-stage.

The strategic value of model registries lies in their enabling function. A registry alone doesn't prevent harm—but it provides the information foundation for safety requirements, pre-deployment review, incident tracking, and international coordination. Without knowing what models exist and what capabilities they possess, governments cannot effectively regulate AI development. Model registries transform AI governance from reactive to proactive by creating visibility into the development pipeline before deployment.

## Current Implementation Landscape

### United States

**Federal Level:**
The October 2023 Executive Order directed the Bureau of Industry and Security (BIS) to establish reporting requirements for advanced AI models. Under the proposed rule:
- Entities must report models trained with >10^26 FLOP
- Quarterly reporting on training activities
- Six-month forward-looking projections required
- Information includes ownership, compute access, safety testing

**State Level:**

| State | Legislation | Key Requirements | Status |
|-------|-------------|------------------|--------|
| **California** | TFAIA (AB 2885) | Annual Frontier AI Framework publication; developer accountability | Enacted; effective Jan 1, 2026 |
| **New York** | RAISE Act | 72-hour incident reporting; safety protocol publication; civil penalties up to \$1M | Enacted 2024 |
| **Colorado** | SB 24-205 | High-risk AI system registration; algorithmic impact assessments | Enacted May 2024 |

### European Union

The EU AI Act establishes the most comprehensive registry requirements to date:

- **General-Purpose AI Models**: Registration with EU AI Office if trained >10^25 FLOP
- **High-Risk AI Systems**: Registration in EU database before market placement
- **Systemic Risk Models**: Additional transparency and safety requirements
- **Required Information**: Technical documentation, compliance evidence, intended use

The EU database will be publicly accessible for high-risk AI systems, with confidential technical documentation available to regulators.

### China

China has implemented registration requirements since 2023:

- Deep synthesis (deepfake) algorithms must register with CAC
- Generative AI services require registration before public offering
- Algorithmic recommendation services subject to separate registry
- Focus on content moderation and political sensitivity

### Comparison Table

| Jurisdiction | Compute Threshold | Pre/Post Deployment | Public Access | Penalties |
|--------------|------------------|--------------------|--------------| ----------|
| **US Federal** | 10^26 FLOP | Pre + ongoing | Limited (security) | Under development |
| **California** | Capability-based | Pre-deployment | Framework public | Civil liability |
| **New York** | Scale-based | Pre + incidents | Protocols public | Up to \$1M |
| **EU** | 10^25 FLOP | Pre-market | Partial | Up to 7% revenue |
| **China** | Any public AI | Pre-deployment | Limited | Service suspension |

## Strategic Assessment

### Benefits of Model Registries

| Benefit | Mechanism | Confidence |
|---------|-----------|------------|
| **Visibility for governance** | Know what exists before regulating | High |
| **Incident learning** | Track failures across the ecosystem | High |
| **Pre-deployment review** | Enable safety checks before release | Medium-High |
| **International coordination** | Common information standards | Medium |
| **Enforcement foundation** | Can't enforce rules without knowing who to apply them to | High |
| **Research ecosystem support** | Aggregate data for policy research | Medium |

### Limitations and Challenges

| Challenge | Description | Mitigation |
|-----------|-------------|------------|
| **Threshold gaming** | Developers structure training to avoid thresholds | Multiple thresholds; capability-based triggers |
| **Dual-use concerns** | Registry information could advantage competitors/adversaries | Tiered access; confidentiality provisions |
| **Open-source gap** | Registries focus on centralized developers | Post-release monitoring; community registries |
| **Enforcement difficulty** | Verifying submitted information is accurate | Auditing; whistleblower protections |
| **Rapid obsolescence** | Thresholds outdated as technology advances | Automatic update mechanisms; sunset provisions |
| **International gaps** | No global registry; jurisdiction shopping | International coordination (nascent) |

### Relationship to Other Governance Tools

Model registries are necessary but not sufficient for AI governance. They enable but don't replace:

<Mermaid client:load chart={`
flowchart LR
    A[Model Registry] --> B[Pre-Deployment Review]
    A --> C[Safety Certification]
    A --> D[Compute Monitoring]
    A --> E[International Coordination]
    A --> F[Incident Investigation]
    A --> G[Liability Assignment]

    B --> H[Safe Deployment]
    C --> H
    D --> I[Development Oversight]
    E --> J[Global Coordination]
    F --> K[Systemic Learning]
    G --> L[Accountability]

    style A fill:#e1f5ff
    style H fill:#d4edda
    style I fill:#d4edda
    style J fill:#d4edda
    style K fill:#d4edda
    style L fill:#d4edda
`} />

## Implementation Recommendations

### Minimum Viable Registry

For jurisdictions establishing initial AI model registries:

1. **Compute-based threshold**: 10^25-10^26 FLOP (adjustable)
2. **Pre-deployment notification**: 30-90 days before public release
3. **Required information**:
   - Developer identity and contact
   - Training compute and data sources (categorical)
   - Intended use cases and deployment scope
   - Safety evaluation summary
   - Known risks and mitigations
4. **Incident reporting**: 72 hours for critical harms
5. **Annual updates**: Mandatory refresh of all information
6. **Tiered access**: Public summary + confidential technical details

### Best Practices from Research

Based on analysis by Convergence Analysis and the Institute for Law & AI:

| Principle | Rationale | Implementation |
|-----------|-----------|----------------|
| **Minimal burden** | Encourage compliance, reduce resistance | Require only information developers already track |
| **Interoperable** | Enable international coordination | Align with emerging international standards |
| **Updatable** | Technology changes faster than regulation | Built-in mechanism for threshold adjustment |
| **Complementary** | Registry enables other tools, doesn't replace them | Design for integration with safety requirements |
| **Proportionate** | Different requirements for different risk levels | Tiered obligations based on capability/deployment |

### Avoiding Common Pitfalls

**Don't:**
- Set thresholds so high only 2-3 models qualify (too narrow)
- Require disclosure of trade secrets unnecessarily (industry opposition)
- Create registry without enforcement mechanism (toothless)
- Assume static thresholds will remain appropriate (obsolescence)
- Ignore international coordination from the start (jurisdiction shopping)

## Future Trajectory

### Near-Term (2025-2026)

- US federal registry rules finalized
- EU database operational for high-risk AI
- California TFAIA implementation
- 5-10 jurisdictions with some form of registry
- Initial international coordination discussions

### Medium-Term (2027-2030)

- Potential international registry framework
- Capability-based triggers supplement compute thresholds
- Integration with compute monitoring
- Real-time incident reporting systems
- Cross-border data sharing agreements

### Key Uncertainties

| Question | Optimistic Scenario | Pessimistic Scenario |
|----------|--------------------|--------------------|
| International coordination | Common standards, shared database | Fragmented, incompatible systems |
| Enforcement effectiveness | High compliance, meaningful oversight | Widespread evasion, symbolic only |
| Open-source coverage | Community registries, post-release tracking | Unmonitored proliferation |
| Threshold relevance | Adaptive thresholds track real risks | Outdated, easily gamed |

## Quick Assessment

| Dimension | Assessment | Notes |
|-----------|------------|-------|
| **Tractability** | High | Active legislation in multiple jurisdictions |
| **If AI risk high** | High | Essential infrastructure for any governance |
| **If AI risk low** | Medium | Still useful for transparency and accountability |
| **Neglectedness** | Low-Medium | Active policy area but implementation gaps |
| **Timeline to impact** | 1-3 years | Requirements taking effect 2025-2026 |
| **Grade** | B+ | Foundational but not transformative alone |

## Risks Addressed

| Risk | Mechanism | Effectiveness |
|------|-----------|---------------|
| <EntityLink id="racing-dynamics">Racing Dynamics</EntityLink> | Visibility into development timelines | Low-Medium |
| <EntityLink id="misuse-risks">Misuse Risks</EntityLink> | Know what capabilities exist | Medium |
| Regulatory arbitrage | Harmonized international requirements | Low (currently) |
| Incident learning gaps | Mandatory reporting creates database | Medium-High |

## Complementary Interventions

- Compute Governance - Hardware-based verification complements software registration
- <EntityLink id="export-controls">Export Controls</EntityLink> - Control inputs to models in registry
- <EntityLink id="ai-safety-institutes">AI Safety Institutes</EntityLink> - Institutions to review registered models
- <EntityLink id="responsible-scaling-policies">Responsible Scaling Policies</EntityLink> - Industry commitments that registries can verify

## Sources

### Policy Analysis

- **Convergence Analysis (2024):** "AI Model Registries: A Foundational Tool for AI Governance" - Comprehensive design framework
- **Institute for Law & AI (2024):** "The Role of Compute Thresholds for AI Governance" - Threshold design considerations
- **Carnegie Endowment (2025):** "Entity-Based Regulation in Frontier AI Governance" - Alternative regulatory approaches

### Legislation and Regulation

- **US Executive Order 14110 (October 2023):** "Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence"
- **EU AI Act (2024):** Regulation establishing harmonized rules on artificial intelligence
- **California AB 2885 (2024):** Transparency in Frontier Artificial Intelligence Act
- **New York RAISE Act (2024):** Requiring AI Safety and Excellence

### Implementation Resources

- **NIST:** AI Risk Management Framework integration guidance
- **EU AI Office:** High-risk AI database specifications
- **BIS:** Proposed rule on AI model reporting requirements (2024)

---

## AI Transition Model Context

Model registries improve the <EntityLink id="ai-transition-model" /> through <EntityLink id="civilizational-competence" />:

| Factor | Parameter | Impact |
|--------|-----------|--------|
| <EntityLink id="civilizational-competence" /> | <EntityLink id="regulatory-capacity" /> | Provides information foundation for any governance interventions |
| <EntityLink id="civilizational-competence" /> | <EntityLink id="institutional-quality" /> | Enables pre-deployment review and incident learning |
| <EntityLink id="civilizational-competence" /> | <EntityLink id="international-coordination" /> | Common standards facilitate cross-border coordination |

Registries are necessary but not sufficient infrastructure; they enable rather than replace safety requirements, evaluations, and enforcement mechanisms.
