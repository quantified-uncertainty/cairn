---
title: Trust Decline
description: The systematic decline in public confidence in institutions, media, and verification systems—accelerated by AI's capacity to fabricate evidence and exploit epistemic vulnerabilities.
sidebar:
  order: 28
maturity: Growing
quality: 40
llmSummary: "Analyzes trust erosion as an AI risk rather than just a state, documenting how declining institutional confidence (US government: 77% in 1964 → 22% in 2024) undermines coordination on existential risks. Identifies the 'liar's dividend' as a key mechanism where deepfake possibility undermines all evidence, with politicians claiming 'fake news' receiving 8-15% higher support."
lastEdited: "2025-12-29"
importance: 62
seeAlso: societal-trust
causalLevel: pathway
pageTemplate: knowledge-base-risk
todos:
  - Complete 'How It Works' section
  - Complete 'Key Uncertainties' section (6 placeholders)
ratings:
  novelty: 4
  rigor: 5.5
  actionability: 4.5
  completeness: 4
metrics:
  wordCount: 319
  citations: 7
  tables: 6
  diagrams: 0
---
import {DataInfoBox, Backlinks, R, EntityLink, DataExternalLinks} from '../../../../../components/wiki';

<DataExternalLinks pageId="trust-decline" client:load />

<DataInfoBox entityId="trust-decline" />

## Overview

Trust erosion describes the **active process** of declining public confidence in institutions, experts, media, and verification systems. While the current *state* of societal trust is analyzed in the <EntityLink id="societal-trust">Societal Trust</EntityLink> parameter page, this page focuses on trust erosion as a **risk**—examining the threat model, acceleration mechanisms, and responses.

> **For comprehensive data and analysis**, see <EntityLink id="societal-trust">Societal Trust</EntityLink>, which covers:
> - Current trust levels (US government trust: 77% in 1964 → 22% in 2024)
> - International comparisons and benchmarks
> - AI-driven acceleration mechanisms (liar's dividend, deepfakes, scale asymmetry)
> - Factors that increase trust (interventions, C2PA standards, media literacy)
> - Trajectory scenarios through 2030

---

## Risk Assessment

| Dimension | Assessment | Notes |
|-----------|------------|-------|
| **Severity** | High | Undermines democratic governance, collective action on existential risks |
| **Likelihood** | Very High | Already occurring; AI accelerating pre-existing trends |
| **Timeline** | Ongoing | Effects visible now, intensifying over 2-5 years |
| **Trend** | Accelerating | AI content generation scaling faster than verification capacity |
| **Reversibility** | Difficult | Rebuilding trust requires sustained effort over decades |

---

## Why Trust Erosion Is a Risk

Trust erosion threatens AI safety and existential risk response through several mechanisms:

| Domain | Impact | Evidence |
|--------|--------|----------|
| **AI Governance** | Regulatory resistance, lab-government distrust | Only ~40% trust government to regulate AI appropriately (OECD 2024) |
| **Elections** | Contested results, violence | 4 in 10 with high grievance approve hostile activism (<R id="1312df71e6a1ca40">Edelman 2025</R>) |
| **Public Health** | Pandemic response failure | Healthcare trust dropped 30.4 pts during COVID-19 |
| **Climate Action** | Policy paralysis | Only ~40% believe government will reduce emissions effectively |
| **International Cooperation** | Treaty verification failures | Liar's dividend undermines evidence-based agreements |

The core dynamic: **low trust prevents the coordination needed to address catastrophic risks**, while AI capabilities make trust harder to maintain.

---

## Responses That Address This Risk

| Response | Mechanism | Effectiveness |
|----------|-----------|---------------|
| <EntityLink id="content-authentication">Content Authentication</EntityLink> | Cryptographic verification of content origins (C2PA standard) | Medium-High |
| <EntityLink id="epistemic-infrastructure">Epistemic Infrastructure</EntityLink> | Strengthening fact-checking and verification systems | Medium |
| <EntityLink id="epistemic-security">Epistemic Security</EntityLink> | Protecting information ecosystems from manipulation | Medium |
| <EntityLink id="deepfake-detection">Deepfake Detection</EntityLink> | Technical countermeasures to synthetic media | Medium (cat-and-mouse) |
| Media Literacy Programs | Teaching source evaluation and critical thinking | Medium (d=0.60 effect size) |

See <EntityLink id="societal-trust">Societal Trust</EntityLink> for detailed intervention analysis.

---

## Key Acceleration Mechanism: The Liar's Dividend

The most concerning AI-driven dynamic is the **liar's dividend** (<R id="ad6fe8bb9c2db0d9">Chesney & Citron</R>): the mere *possibility* of fabricated evidence undermines trust in *all* evidence. Research shows politicians who falsely claim scandals are "fake news" receive 8-15% higher support than those who apologize (<R id="c75d8df0bbf5a94d">American Political Science Review, 2024</R>).

This creates a double bind where neither belief nor disbelief in evidence can be rationally justified—and the effect will intensify as deepfake capabilities improve.

---

## Related Pages

### Primary Reference
- **<EntityLink id="societal-trust">Societal Trust</EntityLink>** — Comprehensive parameter page with current levels, data, mechanisms, interventions, and scenarios

### Related Risks
- <EntityLink id="epistemic-collapse">Epistemic Collapse</EntityLink> — Catastrophic trust failure scenario
- <EntityLink id="trust-cascade">Trust Cascade</EntityLink> — Cascading institutional trust failures
- <EntityLink id="authentication-collapse">Authentication Collapse</EntityLink> — Verification system breakdown
- <EntityLink id="deepfakes">Deepfakes</EntityLink> — AI capability that accelerates erosion

### Related Parameters
- <EntityLink id="epistemic-health">Epistemic Health</EntityLink> — Collective ability to distinguish truth from falsehood
- <EntityLink id="information-authenticity">Information Authenticity</EntityLink> — Verifiability of information

### Related Interventions
- <EntityLink id="content-authentication">Content Authentication</EntityLink> — C2PA provenance standards
- <EntityLink id="epistemic-infrastructure">Epistemic Infrastructure</EntityLink> — Verification systems

---

## Sources

- <R id="b46b1ce9995931fe">Pew Research Center: Public Trust in Government</R>
- <R id="1312df71e6a1ca40">Edelman Trust Barometer</R>
- <R id="ad6fe8bb9c2db0d9">Chesney & Citron: Deep Fakes—A Looming Challenge</R>
- <R id="c75d8df0bbf5a94d">Liar's Dividend study (APSR, 2024)</R>

<Backlinks entityId="trust-decline" />
