---
title: "Long-term Steady State Quality"
description: "What the world looks like assuming we successfully navigate the AI transition—whether human agency, equitable benefits, democratic governance, and meaningful purpose are preserved."
sidebar:
  order: 2
  label: Steady State
pageType: stub
lastEdited: "2025-12-29"
---
import {Mermaid, Backlinks} from '../../../../../components/wiki';

## Overview

Steady State Quality measures what the world looks like *assuming we successfully avoid catastrophe and complete the AI transition*. This is about the **destination**—the equilibrium state humanity settles into.

Even if we avoid [Acute Risk](/knowledge-base/parameters/outcomes/acute-risk/) entirely and have a [smooth transition](/knowledge-base/parameters/outcomes/transition-smoothness/), we could still end up in a world where humans lack meaningful agency, AI benefits are concentrated among few, or authentic human preferences are manipulated. A "successful" transition to a dystopia is still a failure.

---

## Sub-dimensions

| Dimension | Description | Key Parameters |
|-----------|-------------|----------------|
| **Human Agency Preserved** | People retain meaningful autonomy and genuine choice over their lives | Human Agency, Preference Authenticity |
| **Benefit Distribution** | AI gains are shared equitably rather than concentrated among few | AI Control Concentration, Economic Stability |
| **Democratic Governance** | Legitimate collective decision-making maintained; not captured by narrow interests | Institutional Quality, AI Control Concentration |
| **Human Purpose/Meaning** | People have fulfilling roles and meaningful work, not just idle consumption | Human Expertise, Human Agency |
| **Epistemic Autonomy** | Humans can still think independently and form genuine views | Epistemic Health, Reality Coherence |
| **Diversity Preserved** | Multiple viable ways of life exist; not homogenized monoculture | Preference Authenticity, Human Agency |

---

## What Shapes the Steady State

<Mermaid client:load chart={`
flowchart TD
    subgraph Epistemic["Epistemic Foundation"]
        EH[Epistemic Health]
        PA[Preference Authenticity]
        RC[Reality Coherence]
    end

    subgraph Agency["Human Capacity"]
        HA[Human Agency]
        HE[Human Expertise]
    end

    subgraph Control["Power Distribution"]
        ACC[AI Control Concentration]
        IQ[Institutional Quality]
    end

    EH --> STEADY[Steady State Quality]
    PA --> STEADY
    RC --> STEADY
    HA --> STEADY
    HE --> STEADY
    ACC -->|who controls the future| STEADY
    IQ --> STEADY

    style STEADY fill:#4ecdc4
    style HA fill:#90EE90
    style PA fill:#90EE90
    style EH fill:#90EE90
`} />

### Primary Contributing Aggregates

| Aggregate | Relationship | Mechanism |
|-----------|--------------|-----------|
| [Epistemic Foundation](/knowledge-base/parameters/aggregates/epistemic-foundation/) | ↓↓↓ Improves quality | Clear thinking, authentic preferences, and shared reality enable good collective choices |
| [Governance Capacity](/knowledge-base/parameters/aggregates/governance-capacity/) | ↓↓ Improves quality | Effective institutions shape beneficial long-term structures |
| [Societal Adaptability](/knowledge-base/parameters/aggregates/societal-adaptability/) | ↓ Improves quality | Preserved human capacity maintains agency and purpose |

### Key Individual Parameters

| Parameter | Effect | Strength |
|-----------|--------|----------|
| [Human Agency](/knowledge-base/parameters/human-agency/) | ↓ Improves | ↓↓↓ Critical |
| [Preference Authenticity](/knowledge-base/parameters/preference-authenticity/) | ↓ Improves | ↓↓↓ Critical |
| [AI Control Concentration](/knowledge-base/parameters/ai-control-concentration/) | ↑/↓ Depends | ↑↑↑ Critical (who controls matters) |
| [Epistemic Health](/knowledge-base/parameters/epistemic-health/) | ↓ Improves | ↓↓ Strong |
| [Institutional Quality](/knowledge-base/parameters/institutional-quality/) | ↓ Improves | ↓↓ Strong |
| [Reality Coherence](/knowledge-base/parameters/reality-coherence/) | ↓ Improves | ↓↓ Strong |
| [Human Expertise](/knowledge-base/parameters/human-expertise/) | ↓ Improves | ↓ Moderate |
| [Economic Stability](/knowledge-base/parameters/economic-stability/) | ↓ Improves | ↓ Moderate |

---

## Why This Matters

The steady state is what *persists*:
- **Lock-in effects**: Once established, equilibria are hard to change
- **Revealed preferences**: Current choices shape long-term structures
- **Irreversibility**: Some steady states preclude future alternatives
- **Values matter**: Technical success (avoiding catastrophe) isn't enough if we lose what we value

This outcome dimension asks: "Even if we avoid disaster, will the future be worth living in?"

---

## Key Trade-offs

| Trade-off | Description |
|-----------|-------------|
| **Safety vs. Agency** | Maximum safety might require ceding control to AI systems, reducing human agency |
| **Efficiency vs. Purpose** | Optimal AI allocation might leave humans without meaningful roles |
| **Coordination vs. Diversity** | Global coordination might homogenize cultures and ways of life |
| **Speed vs. Deliberation** | Faster AI development might lock in suboptimal values before we understand implications |

---

## Related Outcomes

- [Acute Risk / Catastrophic Loss](/knowledge-base/parameters/outcomes/acute-risk/) — Must avoid this to reach any steady state
- [Transition Smoothness](/knowledge-base/parameters/outcomes/transition-smoothness/) — The journey affects the destination

---

## Related Parameters

### Aggregate Parameters
- [Epistemic Foundation](/knowledge-base/parameters/aggregates/epistemic-foundation/)
- [Governance Capacity](/knowledge-base/parameters/aggregates/governance-capacity/)
- [Societal Adaptability](/knowledge-base/parameters/aggregates/societal-adaptability/)

<Backlinks entityId="steady-state" />
