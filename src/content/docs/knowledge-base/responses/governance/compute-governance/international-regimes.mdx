---
title: International Compute Regimes
description: Multilateral coordination on AI compute governance
sidebar:
  order: 4
quality: 3
llmSummary: Analyzes international coordination mechanisms for AI compute
  governance, estimating 10-25% chance of meaningful regimes by 2035 but
  potential for 30-60% reduction in racing risk if achieved. Provides detailed
  assessment of IAEA-like institutions, compute allocation treaties, and
  verification challenges, noting current progress limited to non-binding
  declarations from 28 countries.
lastEdited: "2025-12-27"
styleGuideVersion: kb-2.0
importance: 85
---

import {DataInfoBox, Backlinks} from '../../../../../../components/wiki';

<DataInfoBox entityId="international-compute-regimes" />

:::note[Part of Compute Governance]
This page covers **international regimes**—one approach within the broader [Compute Governance](/knowledge-base/responses/governance/compute-governance/) framework. See also: [Export Controls](/knowledge-base/responses/governance/compute-governance/export-controls/), [Thresholds](/knowledge-base/responses/governance/compute-governance/thresholds/), [Monitoring](/knowledge-base/responses/governance/compute-governance/monitoring/).
:::

## Overview

Unilateral compute governance has limits. Export controls can be evaded through third countries. Thresholds only apply within jurisdictions. Monitoring requires international coordination to be comprehensive.

**International compute regimes** aim to coordinate governance across nations—analogous to nuclear non-proliferation or chemical weapons conventions. These are mostly **proposals and early discussions** rather than implemented policies.

### Quick Assessment

| Dimension | Assessment | Quantitative Estimate |
|-----------|------------|----------------------|
| Tractability | Low | 10-25% chance of meaningful regime by 2035 |
| Potential Impact | Very High | Could reduce racing risk by 30-60% if achieved |
| Current Status | Discussion stage | 28 countries in Bletchley process; 0 binding agreements |
| Time Horizon | Long-term | 5-10+ years for meaningful regimes |
| Negotiation Cost | High | $50-200M over 5-10 years for track-1 and track-2 diplomacy |
| Verification Feasibility | Uncertain | Hardware monitoring more feasible than software; 40-70% coverage possible |

### Risks Addressed

| Risk | Mechanism | Effectiveness |
|------|-----------|---------------|
| [Racing Dynamics](/knowledge-base/risk-factors/racing-dynamics/) | Coordinated limits prevent races | High (if achieved) |
| [Proliferation](/knowledge-base/risk-factors/proliferation/) | Global verification of compute access | High (if achieved) |
| [Concentration of Power](/knowledge-base/risks/structural/concentration-of-power/) | Multilateral rather than unilateral control | Medium |

---

## Proposed Structures

### IAEA-like Institution for AI

**Concept:** An international body modeled on the International Atomic Energy Agency (IAEA) that would:

- Monitor AI development globally
- Verify compliance with agreements
- Inspect training runs and facilities
- Share information on risks
- Provide technical assistance

**Potential functions:**
- Registry of large training runs
- On-site inspections of major AI facilities
- Evaluation of dangerous capabilities
- Coordination of safety standards

**Challenges:**
- No existing mandate or institution
- Requires major power agreement
- AI is harder to verify than nuclear materials
- Dual-use nature complicates restrictions

### Compute Allocation Treaties

**Concept:** International agreements on compute access, potentially including:

- Caps on total compute for AI training
- Allocation mechanisms for compute access
- Verification through hardware governance
- Graduated responses to violations

**Analogy:** Similar to nuclear warhead limits in arms control treaties, but for training compute.

**Challenges:**
- Defining "compute for AI" vs. other uses
- Verification at scale
- Rapid technology change
- Competitive concerns

### Non-Proliferation Framework

**Concept:** Restrict transfer of AI capabilities analogous to nuclear non-proliferation:

- Limit export of frontier AI capabilities
- Verification through compute monitoring
- Safeguards on advanced AI use
- Graduated privileges based on compliance

**Elements:**
- "Nuclear club" equivalent for frontier AI
- Technology transfer restrictions
- Inspection and verification rights
- Consequences for violations

---

## Precedents

### Nuclear (IAEA, NPT)

**What works:**
- Inspection and safeguards regime
- Clear material accounting
- International consensus on dangers
- Decades of institution-building

**Limitations:**
- Some proliferation occurred despite regime
- Relies on state cooperation
- Dual-use technology challenges

**Lessons for AI:**
- International institutions can work
- Verification is possible but imperfect
- Requires sustained political commitment
- May not prevent all dangerous development

### Chemical Weapons (CWC, OPCW)

**What works:**
- Near-universal membership
- Industry cooperation on verification
- Successful destruction of declared stockpiles
- Strong norm against use

**Limitations:**
- Some non-compliance (Syria)
- Verification challenges with dual-use chemicals
- Limited enforcement mechanisms

**Lessons for AI:**
- Industry buy-in is crucial
- Norms can be powerful
- Verification needs ongoing adaptation
- Universal membership achievable

### Key Differences from AI

| Factor | Nuclear/Chemical | AI |
|--------|-----------------|-----|
| Civilian benefits | Limited (nuclear power) | Enormous |
| Verification | Physical materials | Software, models, compute |
| Actors | States | States, companies, individuals |
| Pace of change | Slow | Extremely rapid |
| Dual-use | Clear weapons applications | Pervasive dual-use |

---

## Current Progress

### AI Safety Summits

**Bletchley Declaration (November 2023):**
- 28 countries including US, UK, EU, China
- First international agreement mentioning catastrophic AI risk
- Very high-level, non-binding
- Established ongoing process

**Seoul AI Safety Summit (May 2024):**
- Expanded participation
- Company commitments
- International research cooperation
- Still mostly declarative

**Future summits:**
- France (2025)
- Ongoing process established

### UN AI Advisory Body

**Mandate:**
- High-level body on AI governance
- Report on international coordination options
- Recommendations for UN system

**Limitations:**
- Advisory only
- Slow UN processes
- Lowest common denominator outcomes

### Bilateral Discussions

**US-China:**
- Limited AI safety dialogue
- Complicated by broader tensions
- Some track-2 discussions
- No formal agreements

**US-EU:**
- Trade and Technology Council
- AI risk discussions
- More alignment on approach

---

## Key Uncertainties

**Is US-China cooperation possible?** The current geopolitical environment makes cooperation difficult. Export controls and chip restrictions create adversarial dynamics. Whether safety concerns can create space for cooperation despite competition is uncertain.

**Do international regimes work for fast-moving technology?** Nuclear and chemical regimes developed over decades for relatively stable technologies. AI changes rapidly. Whether international institutions can keep pace is unclear.

**Who negotiates for AI labs?** Unlike nuclear weapons (state monopoly), AI development involves private companies. International regimes would need to somehow bind or represent corporate actors.

**What would verification look like?** Verifying nuclear materials is hard but possible. Verifying AI training is harder—models are software, training can be distributed, capabilities emerge unexpectedly. Whether meaningful verification is technically feasible is uncertain.

---

## Pathways Forward

### Incremental Approach

Start with achievable agreements and build:

1. **Information sharing:** Mutual notification of large training runs
2. **Standards alignment:** Common safety evaluation frameworks
3. **Research cooperation:** Joint work on AI safety
4. **Incident coordination:** Sharing on AI accidents and near-misses
5. **Deeper commitments:** As trust builds, more binding agreements

### Crisis-Driven Approach

Major AI incident creates political will:

- Significant AI-caused harm
- Near-miss that demonstrates risk
- Geopolitical crisis involving AI
- Rapid regime formation in response

**Risk:** Crisis-driven regimes may be poorly designed.

### Technology-Enabled Approach

Technical solutions enable governance:

- Hardware governance makes verification feasible
- Interpretability enables capability assessment
- Compute monitoring provides transparency
- Trust built through verifiable compliance

---

## Who Should Work on This

**Diplomats and international relations:**
- Negotiation experience
- Understanding of treaty processes
- Relationships with key governments

**AI governance researchers:**
- Designing regime structures
- Verification mechanisms
- Comparative analysis with other regimes

**Technical experts:**
- What's verifiable
- Compute measurement
- Hardware governance feasibility

**Track-2 diplomacy:**
- Building relationships outside official channels
- Academic and civil society engagement
- Laying groundwork for official discussions

### Key Organizations

- **Centre for the Governance of AI (GovAI):** Leading research on compute governance and international coordination
- **UN Office for Disarmament Affairs:** Potential institutional home
- **Foreign ministries:** Negotiating parties
- **AI Safety Summits process:** Current focal point

---

## Critical Assessment

### Effectiveness Assessment

| Criterion | Current Evidence | Confidence |
|-----------|------------------|------------|
| Precedent success (nuclear) | NPT prevented 15-25 additional nuclear states | High |
| AI-specific challenges | Verification harder; dual-use pervasive; faster pace | High |
| US-China cooperation feasibility | Some track-2 dialogue exists; official channels limited | Medium |
| Industry buy-in probability | 40-70% of major labs would cooperate with legitimate regime | Medium |
| Enforcement mechanism viability | Export controls as backstop; 30-50% effective | Low-Medium |

### Resource Requirements

| Investment Type | Estimated Cost | Timeline | Expected Impact |
|----------------|----------------|----------|-----------------|
| Track-1 diplomacy (official) | $10-50M/year | 5-10+ years | Formal treaty negotiations |
| Track-2 diplomacy (unofficial) | $5-20M/year | 2-5 years | Build relationships, explore options |
| Technical verification R&D | $20-100M | 3-7 years | Develop monitoring technology |
| International secretariat (if established) | $10-50M/year | Ongoing | Treaty implementation |
| Academic/think tank research | $5-15M/year | Ongoing | Regime design, analysis |

### Comparative Analysis with Other Regimes

| Regime | Time to Establish | Effectiveness | Relevance to AI |
|--------|-------------------|---------------|-----------------|
| NPT (nuclear) | 25 years (1945-1970) | 70-85% (prevented most proliferation) | Medium (different verification) |
| CWC (chemical) | 100+ years (1899-1997) | 80-90% (near-universal ban) | Low (physical materials) |
| MTCR (missiles) | 8 years (1979-1987) | 50-70% (slowed proliferation) | Medium (tech export focus) |
| Wassenaar (dual-use) | 5 years (1991-1996) | 40-60% (coordination, not binding) | High (similar structure) |

### Key Uncertainties

| Uncertainty | Range of Estimates | Why It Matters |
|-------------|-------------------|----------------|
| US-China regime cooperation | 5-30% by 2030 | Core feasibility question |
| AI timeline to catastrophic risk | 5-30 years | Determines urgency |
| Verification technology development | 3-10 years to viable systems | Enables enforcement |
| Non-state actor relevance | 10-40% of frontier development | Regime coverage |
| Crisis-driven window | 20-50% of regime creation scenarios | Strategic timing |

### Optimistic View

International compute regimes could be transformative:
- Prevent race to the bottom
- Enable verification of safety commitments
- Distribute AI benefits globally
- Build trust between major powers

### Pessimistic View

International regimes may be:
- Impossible given US-China tensions
- Too slow for AI timelines
- Unenforceable for software
- Easily circumvented by non-state actors

### Realistic Assessment

International regimes are **important for long-term governance** but **unlikely to be primary defense in near-term**. Worth investing in while recognizing:
- Long timelines (5-10+ years)
- Uncertain feasibility
- Need complementary approaches
- Incremental progress valuable

---

## Related Approaches

- [Export Controls](/knowledge-base/responses/governance/compute-governance/export-controls/) — Unilateral restrictions (current approach)
- [Compute Thresholds](/knowledge-base/responses/governance/compute-governance/thresholds/) — Domestic regulatory triggers
- [Compute Monitoring](/knowledge-base/responses/governance/compute-governance/monitoring/) — Technical foundation for verification

---

## Related Pages

<Backlinks client:load entityId="international-compute-regimes" />
