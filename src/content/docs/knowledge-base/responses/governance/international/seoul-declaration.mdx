---
title: Seoul AI Safety Summit Declaration
description: May 2024 international commitments on frontier AI safety
sidebar:
  order: 9
quality: 3
llmSummary: The Seoul AI Safety Summit produced voluntary commitments from 28
  countries and 16 AI companies on safety practices, transparency, and incident
  reporting, plus established an international AI Safety Institute network.
  While representing incremental progress with 70-80% expected compliance on
  safety frameworks, the lack of binding commitments and enforcement mechanisms
  limits effectiveness, with only 10-30% chance of translating to binding
  agreements within 5 years.
lastEdited: "2025-12-27"
importance: 75.5
---

import {DataInfoBox} from '../../../../../../components/wiki';

<DataInfoBox entityId="seoul-declaration" />

## Quick Assessment

| Dimension | Assessment | Quantitative Estimate |
|-----------|------------|----------------------|
| **Country Participation** | Strong | 28 countries + EU signed declaration |
| **Company Participation** | Broad | 16 AI companies signed Frontier AI Safety Commitments |
| **Binding Force** | None | 0 legally enforceable provisions |
| **Progress from Bletchley** | Incremental | ~20-30% more concrete than predecessor |
| **Implementation Likelihood** | Low-Medium | 30-50% of company commitments expected to be fully implemented |

## Summary

The **Seoul AI Safety Summit** (May 21-22, 2024) was the second in a series of international AI safety summits, following the **Bletchley Park Summit** in November 2023.

The summit produced multiple outcome documents representing incremental progress on international AI governance, though critics note the commitments remain largely voluntary.

## Key Outcomes

### 1. Seoul Declaration

A high-level political statement signed by 28 countries plus the EU, reaffirming:
- Recognition of frontier AI risks
- Commitment to international cooperation
- Support for science-based risk assessment
- Need for both safety and innovation

### 2. Frontier AI Safety Commitments

**16 AI companies** signed commitments to:

**Safety practices**:
- Publish safety frameworks (RSPs or equivalents)
- Conduct pre-deployment safety evaluations
- Establish internal accountability structures

**Transparency**:
- Share information on capabilities and limitations
- Provide transparency on safety practices
- Support external evaluation efforts

**Incident reporting**:
- Share information about safety incidents
- Support development of common reporting standards

**Participating companies**:
Amazon, Anthropic, Cohere, Google, G42, IBM, Inflection AI, Meta, Microsoft, Mistral AI, Naver, OpenAI, Samsung Electronics, Technology Innovation Institute, xAI, Zhipu AI

### 3. AI Safety Institute Network

Agreement to establish an **international network of AI Safety Institutes**, including:
- Information sharing between national institutes
- Coordinated evaluation methodologies
- Joint research initiatives
- Personnel exchanges

**Participating institutes**:
- UK AI Safety Institute
- US AI Safety Institute
- Planned institutes in Japan, Singapore, Canada, EU, others

### 4. Scientific Statement

An international scientific statement on AI safety endorsed by experts, noting:
- Current limitations in understanding AI systems
- Need for improved evaluation methods
- Importance of interpretability research
- Uncertainty about future capability trajectories

## Progress from Bletchley

| Topic | Bletchley (Nov 2023) | Seoul (May 2024) |
|-------|---------------------|------------------|
| Declaration | 28 signatories | 28 signatories |
| Company commitments | None formal | 16 companies signed |
| AI Safety Institutes | UK announced | International network agreed |
| Specificity | General principles | More detailed commitments |

## Limitations and Critiques

**What's missing**:
- **No binding commitments**: All voluntary
- **No enforcement mechanism**: Relies on good faith
- **No specific thresholds**: Vague on what triggers requirements
- **China's limited participation**: Present but not signing company commitments
- **No liability provisions**: Companies not legally accountable

**Structural concerns**:
- Summit format produces declarations, not treaties
- Commitments may not survive competitive pressure
- No mechanism for handling non-compliance
- Uneven implementation across countries

## Company Commitments Analysis

The company commitments were notable but limited:

**Positive aspects**:
- First coordinated international corporate commitments
- Chinese company (Zhipu AI) participation
- Public accountability mechanism

**Concerns**:
- Commitments largely codify existing practices
- No independent verification requirement
- Vague language allows flexible interpretation
- No consequences for violation

## Significance

The Seoul Summit represents:

1. **Institutionalization**: AI safety summits becoming regular international events
2. **Expansion**: More countries and companies engaged
3. **Specificity**: Moving from principles to (soft) commitments
4. **Network building**: AI Safety Institute cooperation formalized

However, the gap between **summit declarations** and **effective governance** remains large. The summits are building diplomatic infrastructure that could eventually support binding commitments, but that transition has not yet occurred.

## Next Steps

**Paris AI Action Summit** (February 2025):
- Focus on AI for public interest
- Further development of international cooperation
- Possible additional commitments

The summit series aims to maintain momentum on international AI governance while the technology and political landscape evolve.

## Critical Assessment

### Effectiveness Assessment

| Outcome Component | Implementation Status | Expected Compliance | Confidence |
|-------------------|----------------------|--------------------| ------------|
| Safety frameworks published | 3-4 labs have RSPs; others varying | 70-80% of signatories | Medium |
| Pre-deployment evaluations | Conducted by major labs | 50-60% rigor expected | Low-Medium |
| Incident information sharing | Very limited to date | 20-30% meaningful sharing | Low |
| AI Safety Institute network | UK/US operational; others forming | 60-70% capacity by 2026 | Medium |
| Transparency on capabilities | Model cards common but inconsistent | 40-50% meaningful disclosure | Medium |

### Resource Requirements

| Initiative | Investment | Timeline | Expected Outcome |
|------------|-----------|----------|------------------|
| Company compliance monitoring | $2-5M/year | Ongoing | Track implementation of 16-company commitments |
| AISI network coordination | $5-15M/year | 2-3 years | Harmonized evaluation standards |
| Follow-up summit (Paris 2025) | $10-25M | 6 months | Incremental progress, expanded participation |
| Independent verification system | $10-30M setup | 2-4 years | Credible compliance assessment |
| Binding treaty negotiation | $50-100M+ (diplomatic effort) | 5-10 years | Enforceable international framework |

### Key Uncertainties

| Uncertainty | Range of Estimates | Impact on Assessment |
|-------------|-------------------|---------------------|
| Commitment durability | 40-70% hold for 2+ years | High - determines real-world value |
| China's next steps | Will participate vs. disengage (30-60% engagement) | High - critical for global coverage |
| Verification feasibility | 30-50% of commitments verifiable | Medium - affects accountability |
| Competitive pressure effects | Major defection probability: 15-35% | High - could collapse framework |
| Translation to binding agreements | 10-30% chance within 5 years | High - ultimate goal of summit process |

### Progress Metrics

| Metric | Bletchley (Nov 2023) | Seoul (May 2024) | Change |
|--------|---------------------|------------------|--------|
| Countries participating | 28 | 28 + EU | Stable |
| Company commitments | None formal | 16 companies | Significant |
| Specific requirements | Very vague | More specific (RSPs, evaluations) | Moderate |
| AI Safety Institutes | UK announced | Network of 5+ established/planned | Significant |
| Enforcement mechanism | None | None | No change |
| Chinese company participation | None | 1 (Zhipu AI) | Minor |

