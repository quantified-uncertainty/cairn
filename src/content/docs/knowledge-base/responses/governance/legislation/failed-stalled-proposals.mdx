---
title: Failed and Stalled AI Policy Proposals
description: AI governance initiatives that were rejected, vetoed, or stalled
sidebar:
  order: 15
quality: 3
llmSummary: Analyzes patterns in failed AI governance proposals including
  California's SB 1047 veto and stalled federal legislation, finding that
  incremental approaches with industry support are more likely to succeed than
  comprehensive frameworks (50+ federal bills introduced with <5% passage rate).
  Documents systematic industry opposition spending $100-200M annually and
  identifies key failure patterns including definitional challenges,
  jurisdictional complexity, and speed mismatches between technology and policy
  development.
lastEdited: "2025-12-27"
importance: 75.2
---import {DataInfoBox} from '../../../../../../components/wiki';

<DataInfoBox entityId="failed-stalled-proposals" />

## Quick Assessment

| Dimension | Assessment | Quantitative Estimate |
|-----------|------------|----------------------|
| **Failed US State Bills** | Multiple vetoed or stalled | 3-5 major proposals per year |
| **Federal AI Bills Introduced** | High volume, low passage | 50+ bills, less than 5% passage rate |
| **Industry Lobbying Spend** | Substantial opposition resources | $100-200M annually on AI policy |
| **Revival Probability (SB 1047)** | Medium | 30-50% similar bill within 2 years |
| **International Treaty Progress** | Minimal binding agreements | 0 comprehensive AI treaties |
| **Average Legislative Cycle** | Multi-year for comprehensive bills | 2-4 years from introduction to enactment |

## Summary

Understanding why AI governance proposals fail is as important as understanding successes. Failed efforts reveal political constraints, industry opposition patterns, and the challenges of regulating rapidly evolving technology.

## United States

### California SB 1047 (Vetoed, 2024)

**What it proposed**: Safety testing requirements for frontier AI models above compute/cost thresholds; liability for critical harms; shutdown capability requirements.

**Outcome**: Passed California legislature; vetoed by Governor Newsom on September 29, 2024.

**Why it failed**:
- **Industry opposition**: Major tech companies (Google, Meta, OpenAI) opposed; Anthropic initially supportive but later ambiguous
- **Federal preemption concerns**: Governor cited preference for federal regulation
- **Innovation fears**: Claims it would drive AI development out of California
- **Startup concerns**: Worry about compliance burden despite exemptions
- **Definitional challenges**: Difficulty defining "covered models" precisely

**Lessons learned**:
- State-level frontier AI regulation faces federal preemption arguments
- Industry can mobilize effectively against specific legislation
- Liability provisions are particularly contentious
- Bipartisan support is possible but not sufficient

### Federal AI Legislation (Stalled, 2023-2024)

**What was proposed**: Multiple federal AI bills introduced in Congress:
- Algorithmic Accountability Act
- AI Labeling Act
- SAFE Innovation Framework
- National AI Commission Act

**Outcome**: No comprehensive federal AI legislation passed as of late 2024.

**Why stalled**:
- **Congressional dysfunction**: General difficulty passing legislation
- **Definitional debates**: No consensus on what counts as "AI"
- **Jurisdictional conflicts**: Multiple committees claim authority
- **Industry lobbying**: Effective opposition to binding requirements
- **Partisan divisions**: Different priorities (safety vs. competition vs. civil rights)

### NIST AI Safety Consortium Mandatory Participation (Not Adopted)

**What was proposed**: Making participation in AISIC mandatory for government contractors.

**Outcome**: Remained voluntary.

**Why not adopted**:
- Industry preference for voluntary approaches
- Concerns about excluding smaller participants
- Questions about NIST's enforcement capacity

## International

### UN Binding AI Treaty (Not Achieved)

**What was proposed**: Binding international agreement on AI governance, analogous to nuclear or biological weapons treaties.

**Outcome**: UN activities have produced reports and advisory bodies but no binding treaty.

**Why not achieved**:
- **Great power competition**: US-China tensions prevent cooperation
- **Definitional challenges**: No agreement on what to regulate
- **Verification difficulties**: How would compliance be monitored?
- **Speed of development**: Technology moves faster than diplomacy
- **Sovereignty concerns**: Nations resist external constraints on strategic technology

### G7 AI Code of Conduct (Limited Impact)

**What was proposed**: The October 2023 Hiroshima AI Process produced a voluntary code of conduct for AI developers.

**Outcome**: Published but with limited observable impact on industry behavior.

**Why limited impact**:
- Voluntary and non-binding
- Vague commitments without specific requirements
- No enforcement mechanism
- Industry already making similar voluntary commitments

### EU AI Act Narrow Scope for Foundation Models (Partially)

**What was proposed**: Early drafts of EU AI Act focused primarily on specific use cases, not foundation models.

**Outcome**: Final act included foundation model provisions, but some argue they remain insufficient.

**Contested areas**:
- Definition of "systemic risk" models
- Open source exemptions
- Enforcement timelines

## Common Failure Patterns

### 1. Industry Opposition

Most failed proposals faced significant industry lobbying:
- **Direct lobbying**: Company representatives meeting with legislators
- **Astroturfing**: Industry-funded groups appearing grassroots
- **Job threat narratives**: Claims regulation will eliminate jobs or drive companies away
- **Innovation rhetoric**: Framing regulation as anti-innovation

### 2. Definitional Challenges

AI is hard to define legally:
- What distinguishes AI from traditional software?
- How to define "frontier" or "advanced" AI?
- How to future-proof definitions as technology evolves?

### 3. Jurisdictional Complexity

Multiple regulatory bodies claim authority:
- In US: FTC, SEC, CFTC, FDA, state AGs, and more
- Internationally: No clear lead institution
- Creates regulatory gaps and inconsistency

### 4. Speed Mismatch

Technology evolves faster than policy:
- By the time legislation passes, it may address yesterday's problems
- Rapid capability improvements outpace regulatory understanding
- New modalities (multimodal, agents) create new challenges

### 5. Collective Action Problems

Even when stakeholders agree on goals:
- First-mover disadvantage for strict regulators
- Race to the bottom dynamics internationally
- Difficulty coordinating across jurisdictions

## What Successful Proposals Share

Looking at what passes vs. what fails:

| Successful | Failed |
|-----------|--------|
| Narrow scope | Broad scope |
| Existing institutional authority | New institutional requirements |
| Industry-acceptable | Strong industry opposition |
| Bipartisan or non-partisan framing | Partisan coding |
| Clear definitions | Ambiguous terms |
| Disclosure requirements | Liability provisions |
| Voluntary or soft law | Hard mandates |

## Implications

The pattern of failures suggests:

1. **Incremental approaches** are more likely to succeed than comprehensive frameworks
2. **Disclosure and transparency** requirements face less opposition than liability
3. **Voluntary commitments** may be necessary stepping stones to mandatory regulation
4. **State-level action** in the US faces federal preemption challenges
5. **International coordination** requires US-China cooperation, which is currently lacking

## Critical Assessment

### Effectiveness Assessment

| Criteria | Current Evidence | Confidence |
|----------|------------------|------------|
| **SB 1047 revival likelihood** | Similar proposals being drafted | Medium |
| **Federal breakthrough probability** | Sectoral more likely than comprehensive | Medium |
| **Industry opposition patterns** | Consistent across proposals | High |
| **Bipartisan support durability** | Fragile coalition | Medium |
| **International treaty feasibility** | US-China tensions persist | High |
| **Voluntary framework adequacy** | Industry commitments remain non-binding | High |

### Legislative Failure Timeline

| Proposal | Key Date | Outcome |
|----------|----------|---------|
| California SB 1047 | September 29, 2024 | Vetoed by Governor Newsom |
| Canada AIDA | January 2025 | Died on order paper |
| US Federal AI Bills | 2023-2024 | Multiple stalled in committee |
| UN Binding AI Treaty | 2023-2024 | No progress toward binding agreement |
| G7 AI Code of Conduct | October 2023 | Published but limited impact |

### Key Uncertainties

| Uncertainty | Range of Outcomes | Impact on Effectiveness |
|-------------|-------------------|------------------------|
| **2025-2026 US elections** | Pro-regulation vs. anti-regulation | High - federal action likelihood |
| **Major AI incident** | None vs. catalyzing event | High - could shift political will |
| **Industry position evolution** | Continued opposition vs. acceptance | High - passage probability |
| **State momentum** | More states follow Colorado vs. pause | Medium - regulatory patchwork |
| **International norm convergence** | Fragmented vs. aligned approaches | Medium - global governance |
| **Liability framework development** | Rejected vs. accepted over time | High - key sticking point |

