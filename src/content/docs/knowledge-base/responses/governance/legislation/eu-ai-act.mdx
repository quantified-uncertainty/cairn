---
title: EU AI Act
description: Comprehensive AI regulation framework from the European Union
sidebar:
  order: 1
quality: 3
llmSummary: The EU AI Act provides a comprehensive risk-based regulatory
  framework with specific provisions for frontier AI models above 10^25 FLOP,
  including mandatory red-teaming and risk assessments, with maximum penalties
  of €35M or 7% global revenue. The framework establishes important precedents
  for AI governance globally, though effectiveness depends on enforcement
  capacity and threshold gaming concerns.
lastEdited: "2025-12-27"
importance: 85.2
---

import {DataInfoBox, Backlinks} from '../../../../../../components/wiki';

<DataInfoBox entityId="eu-ai-act" />

## Quick Assessment

| Dimension | Assessment | Quantitative Estimate |
|-----------|------------|----------------------|
| **Legislative Status** | In force, phased implementation | Full application by August 2026 |
| **Compliance Cost** | High for high-risk systems | EUR 200K-2M per high-risk system |
| **Affected Entities** | AI providers and deployers in EU market | 100,000+ organizations globally |
| **EU AI Office Budget** | New EU-level enforcement body | EUR 30-50M annually |
| **Maximum Penalties** | Up to 7% global revenue | EUR 35M or 7% turnover |
| **GPAI Systems Affected** | Models above compute threshold | 10-20 foundation models (10^25 FLOP) |

## Summary

The EU AI Act is the world's first comprehensive legal framework for artificial intelligence. Adopted in 2024, it establishes a risk-based approach to AI regulation, with stricter requirements for higher-risk AI systems.

For AI safety, the Act is significant because it includes provisions for "general-purpose AI" (GPAI) and foundation models, including frontier AI systems.

## Risk Categories

The Act classifies AI systems by risk level:

### Unacceptable Risk (Banned)
- Social scoring by governments
- Real-time biometric identification in public (with exceptions)
- Manipulation through subliminal techniques
- Exploitation of vulnerabilities

### High Risk (Strict Requirements)
- Biometric identification systems
- Critical infrastructure management
- Educational and vocational training
- Employment and worker management
- Access to essential services
- Law enforcement
- Migration and border control

### Limited Risk (Transparency)
- Chatbots (must disclose AI)
- Emotion recognition
- Deepfake generation

### Minimal Risk (No Requirements)
- AI-enabled video games
- Spam filters
- Most AI applications

## GPAI and Foundation Models

Special provisions for general-purpose AI:

### All GPAI Models
- Technical documentation
- Transparency requirements
- Copyright compliance

### GPAI with Systemic Risk
Models trained with >10^25 FLOP face additional requirements:
- Model evaluation and adversarial testing
- Incident reporting
- Cybersecurity measures
- Energy consumption reporting

## Frontier AI Provisions

For the most capable models:
- Mandatory red-teaming
- Risk assessment for dangerous capabilities
- Reporting obligations to EU AI Office
- Codes of practice for safety

## Enforcement

- **Fines**: Up to €35M or 7% global revenue
- **EU AI Office**: Oversees GPAI compliance
- **National authorities**: Enforce most provisions
- **Codes of practice**: Industry self-regulation with EU oversight

## Timeline

| Date | Milestone |
|------|-----------|
| April 2021 | Commission proposal |
| December 2023 | Political agreement |
| March 2024 | Parliament approval |
| August 2024 | Entry into force |
| August 2025 | Most provisions apply |
| August 2026 | Full application |

## Criticisms

### From Safety Perspective
- Compute thresholds may be gameable
- 10^25 FLOP threshold may be too high
- Enforcement capacity unclear
- Limited extraterritorial reach

### From Innovation Perspective
- May disadvantage EU companies
- Compliance burden for startups
- Unclear how rules apply in practice

## Critical Assessment

### Effectiveness Assessment

| Criteria | Current Evidence | Confidence |
|----------|------------------|------------|
| **Risk-based approach** | Clear tiering, but threshold debates ongoing | Medium |
| **GPAI provisions** | 10^25 FLOP threshold covers major models | Medium |
| **Enforcement capacity** | EU AI Office being staffed | Medium |
| **Innovation effects** | Early concerns but insufficient data | Low |
| **Brussels Effect** | Other jurisdictions studying EU approach | High |
| **Existential risk coverage** | Limited - focus on near-term harms | Medium |

### Implementation Timeline

| Phase | Dates | Milestones |
|-------|-------|------------|
| Political Agreement | December 2023 | Trilogue conclusion |
| Parliament Approval | March 2024 | Final vote |
| Entry into Force | August 1, 2024 | 20 days after publication |
| Prohibited Practices | February 2025 | Bans take effect |
| GPAI Provisions | August 2025 | Foundation model rules apply |
| High-Risk Systems | August 2026 | Full compliance required |
| Legacy Systems | August 2027 | Existing high-risk systems must comply |

### Key Uncertainties

| Uncertainty | Range of Outcomes | Impact on Effectiveness |
|-------------|-------------------|------------------------|
| **Compute threshold gaming** | Models designed below 10^25 FLOP | High - could undermine GPAI rules |
| **National enforcement variation** | Harmonized vs. fragmented | High - level playing field |
| **Codes of practice quality** | Robust vs. weak industry standards | Medium - GPAI compliance |
| **Open source treatment** | Clear exemptions vs. uncertainty | Medium - innovation ecosystem |
| **Extraterritorial enforcement** | Strong vs. limited reach | High - global impact |
| **Compliance costs realized** | EUR 200K-2M per system | Medium - SME viability |

## Related Pages

<Backlinks client:load entityId="eu-ai-act" />
