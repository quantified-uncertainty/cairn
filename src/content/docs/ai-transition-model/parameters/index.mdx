---
title: "Parameters"
description: "Component parameters that determine the root factors shaping AI transition outcomes. Each parameter can be measured, tracked, and influenced through interventions."
sidebar:
  label: Overview
  order: 0
lastEdited: "2026-01-03"
tableOfContents: false
fullWidth: true
---

import FullWidthLayout from '../../../../components/FullWidthLayout';

<FullWidthLayout />

## Overview

Parameters are the measurable components that determine root factors like [Misalignment Potential](/ai-transition-model/factors/misalignment-potential/) and [Civilizational Competence](/ai-transition-model/factors/civilizational-competence/). Each parameter has:

- **Current state** with quantified metrics
- **Trajectory** showing improvement or decline
- **Factors that increase/decrease** the parameter
- **Connection to outcomes** through parent factors

See the [interactive AI transition model](/ai-transition-model/) for a visual representation.

---

## Parameters by Root Factor

### Misalignment Potential

Parameters determining the likelihood of AI systems pursuing unintended goals.

| Parameter | Description | Current State |
|-----------|-------------|---------------|
| [Alignment Robustness](/ai-transition-model/parameters/alignment-robustness/) | How reliably AI systems pursue intended goals | 12-78% alignment faking in studies |
| [Safety-Capability Gap](/ai-transition-model/parameters/safety-capability-gap/) | Lag between capability and safety advances | Widening (70-80% timeline compression) |
| [Interpretability Coverage](/ai-transition-model/parameters/interpretability-coverage/) | Fraction of model behavior we can explain | ~10% coverage, improving |
| [Human Oversight Quality](/ai-transition-model/parameters/human-oversight-quality/) | Effectiveness of human supervision | Declining relative to AI speed |
| [Safety Culture Strength](/ai-transition-model/parameters/safety-culture-strength/) | Organizational prioritization of safety | Variable (6-12% of R&D) |

### Misuse Potential

Parameters determining vulnerability to intentional harmful use of AI.

| Parameter | Description | Current State |
|-----------|-------------|---------------|
| [AI Control Concentration](/ai-transition-model/parameters/ai-control-concentration/) | Distribution of power over AI development | Concentrating (fewer than 20 frontier-capable orgs) |
| [Biological Threat Exposure](/ai-transition-model/parameters/biological-threat-exposure/) | Vulnerability to AI-enabled bioweapons | ~25% dangerous sequence detection |
| [Cyber Threat Exposure](/ai-transition-model/parameters/cyber-threat-exposure/) | Vulnerability to AI-enabled cyberattacks | 87% of orgs faced AI attacks (2024) |

### Transition Turbulence

Parameters determining background instability during the AI transition.

| Parameter | Description | Current State |
|-----------|-------------|---------------|
| [Economic Stability](/ai-transition-model/parameters/economic-stability/) | Resilience to AI-driven economic changes | 40-60% job exposure in advanced economies |
| [Racing Intensity](/ai-transition-model/parameters/racing-intensity/) | Competitive pressure prioritizing speed over safety | High (safety budgets dropped 12% to 6%) |

### Civilizational Competence

Parameters determining humanity's collective ability to navigate AI development wisely.

#### Governance

| Parameter | Description | Current State |
|-----------|-------------|---------------|
| [Governance](/ai-transition-model/parameters/governance/) | Aggregate capacity to steer AI development | Cross-cutting aggregate |
| [Regulatory Capacity](/ai-transition-model/parameters/regulatory-capacity/) | Government ability to regulate AI | 600:1 resource disparity |
| [Institutional Quality](/ai-transition-model/parameters/institutional-quality/) | Health of AI governance institutions | Under pressure (capture concerns) |
| [International Coordination](/ai-transition-model/parameters/international-coordination/) | Global cooperation on AI governance | Fragmenting (Paris 2025 refusal) |
| [Coordination Capacity](/ai-transition-model/parameters/coordination-capacity/) | Stakeholder cooperation on safety | Growing but limited |

#### Epistemic Foundation

| Parameter | Description | Current State |
|-----------|-------------|---------------|
| [Epistemics](/ai-transition-model/parameters/epistemics/) | Aggregate capacity for clear thinking | Aggregate overview |
| [Epistemic Health](/ai-transition-model/parameters/epistemic-health/) | Ability to distinguish truth from falsehood | 50%+ AI-generated content |
| [Societal Trust](/ai-transition-model/parameters/societal-trust/) | Confidence in institutions and experts | 77% (1964) to 22% (2024) |
| [Reality Coherence](/ai-transition-model/parameters/reality-coherence/) | Shared beliefs about basic facts | 47% to 12% partisan news overlap |
| [Information Authenticity](/ai-transition-model/parameters/information-authenticity/) | Ability to verify content is genuine | 55% human deepfake detection |
| [Preference Authenticity](/ai-transition-model/parameters/preference-authenticity/) | Whether preferences reflect genuine values | 5B+ users on engagement-optimizing systems |

#### Societal Adaptability

| Parameter | Description | Current State |
|-----------|-------------|---------------|
| [Adaptability](/ai-transition-model/parameters/adaptability/) | Aggregate capacity to absorb AI changes | Aggregate overview |
| [Societal Resilience](/ai-transition-model/parameters/societal-resilience/) | Ability to recover from AI disruptions | Declining (outage costs rising) |
| [Human Expertise](/ai-transition-model/parameters/human-expertise/) | Maintenance of human skills | Declining (skill atrophy evidence) |
| [Human Agency](/ai-transition-model/parameters/human-agency/) | Meaningful control over life decisions | Declining (70% YouTube, 75% hiring mediated) |

---

## Related Pages

- [Root Factors](/ai-transition-model/factors/) — The five root factors these parameters determine
- [Outcomes](/ai-transition-model/outcomes/) — Ultimate outcomes shaped by these parameters
- [AI Transition Model](/ai-transition-model/) — Full model overview
