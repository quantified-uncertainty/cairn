---
title: AI Safety Estimates & Expert Positions
description: Comprehensive data on AI timelines, risk estimates, and expert views
sidebar:
  hidden: true
tableOfContents: false
template: splash
---

<div class="dashboard">

<header class="dash-header">
  <h1>AI Safety Estimates</h1>
  <p>Aggregated data from surveys, forecasts, and expert statements</p>
</header>

<section class="key-metrics">
  <div class="metric">
    <div class="metric-main">
      <span class="metric-value blue">10-35%</span>
      <span class="metric-label">TAI by 2030</span>
    </div>
    <span class="metric-source">Metaculus, AI Impacts, Epoch</span>
  </div>
  <div class="metric">
    <div class="metric-main">
      <span class="metric-value blue">40-70%</span>
      <span class="metric-label">AGI by 2040</span>
    </div>
    <span class="metric-source">Expert surveys</span>
  </div>
  <div class="metric">
    <div class="metric-main">
      <span class="metric-value orange">5-30%</span>
      <span class="metric-label">P(Catastrophe)</span>
    </div>
    <span class="metric-source">Without intervention</span>
  </div>
  <div class="metric">
    <div class="metric-main">
      <span class="metric-value red">5-90%</span>
      <span class="metric-label">Expert P(doom) Range</span>
    </div>
    <span class="metric-source">Christiano to Yudkowsky</span>
  </div>
</section>

## Timeline Forecasts

<div class="data-grid">

<div class="data-table">
<h3>Transformative AI by 2030</h3>

| Source | Estimate | Date |
|--------|----------|------|
| Metaculus Community | 25% | 2024 |
| AI Impacts Survey | 10% | 2023 |
| Epoch AI | 15-30% | 2024 |
| Ajeya Cotra (Open Phil) | 35% | 2022 |

**Aggregate: 10-35%**
</div>

<div class="data-table">
<h3>AGI by 2040</h3>

| Source | Estimate | Date |
|--------|----------|------|
| Metaculus Community | 65% | 2024 |
| AI Impacts Survey | 40-50% | 2023 |
| Epoch AI | 55% | 2024 |
| Samotsvety Forecasters | 45% | 2023 |

**Aggregate: 40-70%**
</div>

</div>

## Expert Timeline Views

<div class="expert-grid">
  <div class="expert-card short">
    <span class="expert-name">Dario Amodei</span>
    <span class="expert-org">Anthropic</span>
    <span class="expert-view">2026-2027</span>
    <span class="expert-label">Very Short</span>
  </div>
  <div class="expert-card short">
    <span class="expert-name">Sam Altman</span>
    <span class="expert-org">OpenAI</span>
    <span class="expert-view">2025-2027</span>
    <span class="expert-label">Very Short</span>
  </div>
  <div class="expert-card medium">
    <span class="expert-name">Demis Hassabis</span>
    <span class="expert-org">DeepMind</span>
    <span class="expert-view">Within decade</span>
    <span class="expert-label">Short-Medium</span>
  </div>
  <div class="expert-card medium">
    <span class="expert-name">Paul Christiano</span>
    <span class="expert-org">ARC</span>
    <span class="expert-view">2030s-2040s</span>
    <span class="expert-label">Medium</span>
  </div>
  <div class="expert-card long">
    <span class="expert-name">Gary Marcus</span>
    <span class="expert-org">NYU</span>
    <span class="expert-view">2050+</span>
    <span class="expert-label">Long</span>
  </div>
  <div class="expert-card medium">
    <span class="expert-name">Stuart Russell</span>
    <span class="expert-org">Berkeley</span>
    <span class="expert-view">Decades, uncertain</span>
    <span class="expert-label">Medium-Long</span>
  </div>
</div>

## Risk Estimates (P(doom))

<div class="data-grid">

<div class="data-table">
<h3>Individual Expert Estimates</h3>

| Expert | P(doom) | Date | Notes |
|--------|---------|------|-------|
| Eliezer Yudkowsky | >90% | 2023 | "Doom by default" |
| Paul Christiano | 10-20% | 2022 | Baseline existential risk |
| Dario Amodei | 10-25% | 2023 | Without additional safety work |
| Toby Ord | 10% | 2020 | This century (The Precipice) |
| Yoshua Bengio | 10-15% | 2024 | Significant enough to act |
| Sam Altman | 10-20% | 2023 | But argues building is necessary |

</div>

<div class="data-table">
<h3>Survey Aggregates</h3>

| Source | Estimate | Year |
|--------|----------|------|
| Existential Risk Survey | 10% median | 2023 |
| AI Safety Community | 20-30% | 2024 |
| Anthropic Leadership | 10-25% | 2023 |
| FHI Researchers | 10-20% | 2022 |

</div>

</div>

## Alignment Difficulty

<div class="data-grid">

<div class="data-table">
<h3>Is Alignment Very Hard?</h3>

| Source | P(Hard) | View |
|--------|---------|------|
| MIRI | 80%+ | Current approaches insufficient |
| Anthropic | 30-50% | Tractable with iteration |
| DeepMind | 25-40% | Expects incremental progress |
| Paul Christiano | ~50% | Hard but solvable |
| Stuart Russell | High | Requires paradigm shift |

</div>

<div class="data-table">
<h3>Will Current Techniques Scale?</h3>

| Expert | Estimate | Position |
|--------|----------|----------|
| Eliezer Yudkowsky | 5% | Very unlikely |
| Stuart Russell | 25% | Unlikely without changes |
| Paul Christiano | 40% | Uncertain |
| Jan Leike | 45% | Uncertain |
| Dario Amodei | 60% | Cautiously optimistic |

</div>

</div>

## Warning Signs & Evidence

<div class="evidence-section">

<div class="evidence-item moderate">
  <span class="evidence-signal">Moderate</span>
  <span class="evidence-title">Jailbreaks & prompt injection</span>
  <span class="evidence-desc">Shows robustness problems, but not catastrophic</span>
</div>

<div class="evidence-item moderate">
  <span class="evidence-signal">Moderate</span>
  <span class="evidence-title">Sycophancy</span>
  <span class="evidence-desc">Subtle misalignment with user intent</span>
</div>

<div class="evidence-item high">
  <span class="evidence-signal">High concern</span>
  <span class="evidence-title">Sleeper Agents research (Anthropic 2024)</span>
  <span class="evidence-desc">Demonstrates deception can persist through safety training</span>
</div>

<div class="evidence-item moderate">
  <span class="evidence-signal">Moderate</span>
  <span class="evidence-title">Capability jumps</span>
  <span class="evidence-desc">GPT-3 to GPT-4 had unexpected emergent capabilities</span>
</div>

<div class="evidence-item moderate">
  <span class="evidence-signal">Moderate</span>
  <span class="evidence-title">Emergent deception in games</span>
  <span class="evidence-desc">AI learning to deceive in training environments</span>
</div>

</div>

## Key Disagreements

<div class="disagreement-grid">

<div class="disagreement">
  <h4>Can we iterate to safety?</h4>
  <div class="disagree-row">
    <span class="view-yes">Yes - can learn from failures</span>
    <span class="vs">vs</span>
    <span class="view-no">No - first mistake fatal</span>
  </div>
  <span class="holders">Christiano, Anthropic vs Yudkowsky, MIRI</span>
</div>

<div class="disagreement">
  <h4>Will we get warning signs?</h4>
  <div class="disagree-row">
    <span class="view-yes">Likely - gradual capability gains</span>
    <span class="vs">vs</span>
    <span class="view-no">Unlikely - capabilities hide</span>
  </div>
  <span class="holders">Most researchers vs MIRI</span>
</div>

<div class="disagreement">
  <h4>Is deceptive alignment likely?</h4>
  <div class="disagree-row">
    <span class="view-yes">Detectable if present</span>
    <span class="vs">vs</span>
    <span class="view-no">Very likely, undetectable</span>
  </div>
  <span class="holders">Anthropic, DeepMind vs Yudkowsky</span>
</div>

<div class="disagreement">
  <h4>Should we build frontier AI?</h4>
  <div class="disagree-row">
    <span class="view-yes">Yes, with safety work</span>
    <span class="vs">vs</span>
    <span class="view-no">No - too dangerous</span>
  </div>
  <span class="holders">Labs vs MIRI (post-2022)</span>
</div>

</div>

## Lab Safety Investment (Rough Estimates)

| Lab | Capabilities vs Safety | Notes |
|-----|----------------------|-------|
| Anthropic | 60-40 | Most safety-focused, but commercial needs |
| OpenAI | 80-20 | Superalignment team dissolved 2024 |
| DeepMind | 90-10 | Small dedicated safety team |
| Meta | 95-5 | Primarily capabilities focus |

## Data Sources

- **Metaculus** - Prediction market aggregates ([metaculus.com](https://metaculus.com))
- **AI Impacts** - Expert surveys ([aiimpacts.org](https://aiimpacts.org))
- **Epoch AI** - Compute-based forecasts ([epochai.org](https://epochai.org))
- **The Precipice** - Toby Ord (2020)
- **Public statements** - Lab leadership talks, interviews, blog posts
- **Research publications** - Anthropic, DeepMind safety papers

---

*Last updated: 2024. Estimates change frequently. See original sources for current data.*

</div>

<style>{`
  .dashboard {
    max-width: 1200px;
    margin: 0 auto;
    padding: 1.5rem;
  }

  .dash-header {
    text-align: center;
    margin-bottom: 2rem;
  }

  .dash-header h1 {
    font-size: 2rem;
    margin: 0 0 0.5rem;
    color: var(--sl-color-accent);
  }

  .dash-header p {
    color: var(--sl-color-gray-3);
    margin: 0;
  }

  .key-metrics {
    display: grid;
    grid-template-columns: repeat(4, 1fr);
    gap: 1rem;
    margin-bottom: 2rem;
  }

  @media (max-width: 800px) {
    .key-metrics { grid-template-columns: repeat(2, 1fr); }
  }

  .metric {
    background: var(--sl-color-gray-6);
    border-radius: 0.75rem;
    padding: 1rem;
    text-align: center;
  }

  .metric-main {
    display: flex;
    flex-direction: column;
    margin-bottom: 0.5rem;
  }

  .metric-value {
    font-size: 1.75rem;
    font-weight: 800;
    line-height: 1.1;
  }

  .metric-value.blue { color: #3b82f6; }
  .metric-value.orange { color: #f59e0b; }
  .metric-value.red { color: #ef4444; }

  .metric-label {
    font-size: 0.8rem;
    font-weight: 600;
    color: var(--sl-color-gray-2);
    margin-top: 0.25rem;
  }

  .metric-source {
    font-size: 0.7rem;
    color: var(--sl-color-gray-4);
  }

  .data-grid {
    display: grid;
    grid-template-columns: repeat(2, 1fr);
    gap: 1.5rem;
    margin: 1.5rem 0;
  }

  @media (max-width: 800px) {
    .data-grid { grid-template-columns: 1fr; }
  }

  .data-table {
    background: var(--sl-color-gray-6);
    border-radius: 0.5rem;
    padding: 1rem;
  }

  .data-table h3 {
    font-size: 0.9rem;
    margin: 0 0 0.75rem;
    color: var(--sl-color-text);
  }

  .data-table table {
    width: 100%;
    font-size: 0.8rem;
    border-collapse: collapse;
  }

  .data-table th {
    text-align: left;
    padding: 0.4rem;
    border-bottom: 1px solid var(--sl-color-gray-5);
    font-weight: 600;
    color: var(--sl-color-gray-3);
  }

  .data-table td {
    padding: 0.4rem;
    border-bottom: 1px solid var(--sl-color-gray-5);
  }

  .expert-grid {
    display: grid;
    grid-template-columns: repeat(6, 1fr);
    gap: 0.75rem;
    margin: 1.5rem 0;
  }

  @media (max-width: 900px) {
    .expert-grid { grid-template-columns: repeat(3, 1fr); }
  }

  @media (max-width: 500px) {
    .expert-grid { grid-template-columns: repeat(2, 1fr); }
  }

  .expert-card {
    background: var(--sl-color-gray-6);
    border-radius: 0.5rem;
    padding: 0.75rem;
    display: flex;
    flex-direction: column;
    border-left: 3px solid;
  }

  .expert-card.short { border-color: #ef4444; }
  .expert-card.medium { border-color: #f59e0b; }
  .expert-card.long { border-color: #22c55e; }

  .expert-name {
    font-weight: 600;
    font-size: 0.85rem;
    color: var(--sl-color-text);
  }

  .expert-org {
    font-size: 0.7rem;
    color: var(--sl-color-gray-4);
    margin-bottom: 0.5rem;
  }

  .expert-view {
    font-size: 0.9rem;
    font-weight: 700;
    color: var(--sl-color-accent);
  }

  .expert-label {
    font-size: 0.65rem;
    text-transform: uppercase;
    color: var(--sl-color-gray-3);
  }

  .evidence-section {
    display: flex;
    flex-direction: column;
    gap: 0.5rem;
    margin: 1.5rem 0;
  }

  .evidence-item {
    display: grid;
    grid-template-columns: 100px 200px 1fr;
    gap: 1rem;
    padding: 0.75rem;
    background: var(--sl-color-gray-6);
    border-radius: 0.5rem;
    align-items: center;
    font-size: 0.85rem;
  }

  @media (max-width: 700px) {
    .evidence-item {
      grid-template-columns: 1fr;
      gap: 0.25rem;
    }
  }

  .evidence-signal {
    font-weight: 600;
    font-size: 0.75rem;
    text-transform: uppercase;
  }

  .evidence-item.moderate .evidence-signal { color: #f59e0b; }
  .evidence-item.high .evidence-signal { color: #ef4444; }

  .evidence-title {
    font-weight: 500;
    color: var(--sl-color-text);
  }

  .evidence-desc {
    color: var(--sl-color-gray-3);
    font-size: 0.8rem;
  }

  .disagreement-grid {
    display: grid;
    grid-template-columns: repeat(2, 1fr);
    gap: 1rem;
    margin: 1.5rem 0;
  }

  @media (max-width: 700px) {
    .disagreement-grid { grid-template-columns: 1fr; }
  }

  .disagreement {
    background: var(--sl-color-gray-6);
    border-radius: 0.5rem;
    padding: 1rem;
  }

  .disagreement h4 {
    margin: 0 0 0.75rem;
    font-size: 0.9rem;
    color: var(--sl-color-text);
  }

  .disagree-row {
    display: flex;
    align-items: center;
    gap: 0.5rem;
    margin-bottom: 0.5rem;
    font-size: 0.8rem;
  }

  .view-yes {
    color: #22c55e;
    flex: 1;
  }

  .vs {
    color: var(--sl-color-gray-4);
    font-size: 0.7rem;
  }

  .view-no {
    color: #ef4444;
    flex: 1;
    text-align: right;
  }

  .holders {
    font-size: 0.7rem;
    color: var(--sl-color-gray-4);
  }

  .dashboard h2 {
    font-size: 1.1rem;
    margin: 2rem 0 0.75rem;
    padding-bottom: 0.5rem;
    border-bottom: 1px solid var(--sl-color-gray-5);
    color: var(--sl-color-text);
  }
`}</style>
