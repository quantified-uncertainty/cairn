# Parameter Graph Data
# Defines the nodes and edges for the cause-effect visualization
# Edit this file to update the graph structure

nodes:
  # === ROOT FACTORS (top layer) ===
  # Manual X positions to minimize edge crossings
  # X positions: 0=far left, 1=left-center, 2=center, 3=right-center, 4=far right

  - id: misalignment-potential
    label: AI Misalignment Potential
    description: Potential for AI to be misaligned.
    type: cause
    subgroup: ai
    order: 0
    href: /knowledge-base/ai-transition-model/factors/misalignment-potential/
    subItems:
      - label: Technical AI Safety
      - label: AI Governance
      - label: Lab Safety Practices

  - id: ai-capabilities
    label: AI Capabilities
    description: How powerful AI systems become.
    type: cause
    subgroup: ai
    order: 1
    href: /knowledge-base/ai-transition-model/factors/ai-capabilities/
    subItems:
      - label: Compute
      - label: Algorithmic
      - label: Adoption

  - id: civ-competence
    label: Civilizational Competence
    description: Humanity's ability to respond well.
    type: cause
    subgroup: society
    order: 0
    href: /knowledge-base/ai-transition-model/factors/civilizational-competence/
    subItems:
      - label: Governance
        href: /knowledge-base/ai-transition-model/parameters/governance/
      - label: Epistemics
        href: /knowledge-base/ai-transition-model/parameters/epistemics/
      - label: Adaptability
        href: /knowledge-base/ai-transition-model/parameters/adaptability/

  - id: transition-turbulence
    label: Transition Turbulence
    description: Background instability during transition.
    type: cause
    subgroup: society
    order: 1
    href: /knowledge-base/ai-transition-model/factors/transition-turbulence/
    subItems:
      - label: Economic Stability
        href: /knowledge-base/ai-transition-model/parameters/economic-stability/
      - label: Racing Intensity
        href: /knowledge-base/ai-transition-model/parameters/racing-intensity/

  - id: misuse-potential
    label: Misuse Potential
    description: Potential for AI to be misused for harm.
    type: cause
    subgroup: society
    order: 2
    href: /knowledge-base/ai-transition-model/factors/misuse-potential/
    subItems:
      - label: Biological Threat Exposure
        href: /knowledge-base/ai-transition-model/parameters/biological-threat-exposure/
      - label: Cyber Threat Exposure
        href: /knowledge-base/ai-transition-model/parameters/cyber-threat-exposure/
      - label: Robot Threat Exposure
      - label: Surprise Threat Exposure

  - id: ai-ownership
    label: AI Ownership
    description: Who controls and owns AI systems.
    type: cause
    subgroup: ai
    order: 2
    subItems:
      - label: Countries
      - label: Companies
      - label: Shareholders

  - id: ai-uses
    label: AI Uses
    description: Where and how AI is deployed.
    type: cause
    subgroup: ai
    order: 3
    subItems:
      - label: Recursive AI Capabilities
      - label: Industries
      - label: Governments
      - label: Coordination

  # === ULTIMATE SCENARIOS (middle layer) ===

  - id: ai-takeover
    label: AI Takeover
    description: AI gains decisive control over human affairs.
    type: intermediate
    order: 0
    href: /knowledge-base/ai-transition-model/scenarios/ai-takeover/
    subItems:
      - label: Rapid
        href: /knowledge-base/ai-transition-model/scenarios/ai-takeover/rapid/
      - label: Gradual
        href: /knowledge-base/ai-transition-model/scenarios/ai-takeover/gradual/

  - id: human-catastrophe
    label: Human-Caused Catastrophe
    description: Humans use AI to cause mass harm.
    type: intermediate
    order: 1
    href: /knowledge-base/ai-transition-model/scenarios/human-catastrophe/
    subItems:
      - label: State Actor
        href: /knowledge-base/ai-transition-model/scenarios/human-catastrophe/state-actor/
      - label: Rogue Actor
        href: /knowledge-base/ai-transition-model/scenarios/human-catastrophe/rogue-actor/

  - id: long-term-lockin
    label: Long-term Lock-in
    description: Permanent entrenchment of outcomes.
    type: intermediate
    order: 2
    href: /knowledge-base/ai-transition-model/scenarios/long-term-lockin/
    subItems:
      - label: Economic Power
      - label: Political Power
      - label: Epistemics
      - label: Values
      - label: Suffering Lock-in

  # === ULTIMATE OUTCOMES (bottom layer) ===

  - id: existential-catastrophe
    label: Existential Catastrophe
    description: Civilization-ending or irreversible harm.
    type: effect
    order: 0
    href: /knowledge-base/ai-transition-model/outcomes/existential-catastrophe/

  - id: long-term-trajectory
    label: Long-term Trajectory
    description: Quality of post-transition future.
    type: effect
    order: 1
    href: /knowledge-base/ai-transition-model/outcomes/long-term-trajectory/

edges:
  # Root Factors → Ultimate Scenarios

  - id: e-cap-takeover
    source: ai-capabilities
    target: ai-takeover
    strength: strong
    effect: increases

  - id: e-misalign-takeover
    source: misalignment-potential
    target: ai-takeover
    strength: strong
    effect: increases

  - id: e-misuse-human
    source: misuse-potential
    target: human-catastrophe
    strength: strong
    effect: increases

  - id: e-turb-takeover
    source: transition-turbulence
    target: ai-takeover
    strength: medium
    effect: increases

  - id: e-turb-human
    source: transition-turbulence
    target: human-catastrophe
    strength: medium
    effect: increases

  - id: e-civ-takeover
    source: civ-competence
    target: ai-takeover
    strength: medium
    effect: decreases

  - id: e-civ-human
    source: civ-competence
    target: human-catastrophe
    strength: medium
    effect: decreases

  - id: e-civ-lockin
    source: civ-competence
    target: long-term-lockin
    strength: strong

  - id: e-ownership-lockin
    source: ai-ownership
    target: long-term-lockin
    strength: strong

  - id: e-uses-lockin
    source: ai-uses
    target: long-term-lockin
    strength: strong

  # Ultimate Scenarios → Ultimate Outcomes

  - id: e-takeover-excat
    source: ai-takeover
    target: existential-catastrophe
    strength: strong
    effect: increases

  - id: e-human-excat
    source: human-catastrophe
    target: existential-catastrophe
    strength: strong
    effect: increases

  - id: e-takeover-traj
    source: ai-takeover
    target: long-term-trajectory
    strength: strong
    effect: increases

  - id: e-lockin-traj
    source: long-term-lockin
    target: long-term-trajectory
    strength: strong
